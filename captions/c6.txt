[('./static/6.mp4', 5, u'Okay hi everyone. '), ('./static/6.mp4', 8, u"Let's get started again. "), ('./static/6.mp4', 11, u'Um. Okay. So, first of all for a couple of announcements. '), ('./static/6.mp4', 17, u'Um, first of all thanks to everyone, um, '), ('./static/6.mp4', 20, u"who filled in our mid-quarter survey we've actually gotten, "), ('./static/6.mp4', 23, u'um, great participation in that. '), ('./static/6.mp4', 27, u'Here are my two little Pac-Man figures. '), ('./static/6.mp4', 29, u'So, the Pac-Man figures thinks, '), ('./static/6.mp4', 31, u'means that almost everyone thinks the lectures are at '), ('./static/6.mp4', 34, u"the right pace and those that don't are pretty much evenly divided. "), ('./static/6.mp4', 38, u'Um, if we go for how challenging was Assignment three, '), ('./static/6.mp4', 42, u'slightly more people thought it was too easy than too hard. '), ('./static/6.mp4', 46, u"So, I guess we're setting about rectifying that with "), ('./static/6.mp4', 48, u'assignments four and five, um, [NOISE]. '), ('./static/6.mp4', 53, u"So, though there are a whole bunch of other questions and we've "), ('./static/6.mp4', 56, u'been trying to absorb all the feedback. '), ('./static/6.mp4', 59, u'I mean one of the questions was what people wanted most from the remaining lectures. '), ('./static/6.mp4', 63, u"I guess the good news here is really we're very good at predicting, um, "), ('./static/6.mp4', 69, u'what people wanted, that or else everybody '), ('./static/6.mp4', 71, u'just looked ahead in the syllabus and wrote down what it said was '), ('./static/6.mp4', 74, u'ahead in the syllabus but I guess the most popular four answers to '), ('./static/6.mp4', 79, u'topics that they wanted in the remaining lectures were Transformers and BERT, '), ('./static/6.mp4', 83, u'both of which are gonna be covered this week. '), ('./static/6.mp4', 85, u'Uh, question-answering which we talked about last week, um, '), ('./static/6.mp4', 89, u'and then text generation and summarization '), ('./static/6.mp4', 93, u'and you guys get Abby back next week to talk about that. '), ('./static/6.mp4', 98, u'Um, there are also a lot of people also answered this question '), ('./static/6.mp4', 102, u'a different way as to what kind of style of stuff, '), ('./static/6.mp4', 106, u'um, some people emphasized new research and the latest updates from the field. '), ('./static/6.mp4', 110, u"I guess we'll get some of that today as well, "), ('./static/6.mp4', 113, u'some people are more interested in '), ('./static/6.mp4', 115, u'successful applications in industry or trying to do a bit of that, '), ('./static/6.mp4', 120, u'um, cool new neural architectures. '), ('./static/6.mp4', 122, u"Um, the bottom answer wasn't the most popular one, "), ('./static/6.mp4', 125, u"I'll admit but at least a few people, um, "), ('./static/6.mp4', 128, u'wish that we were teaching more linguistic stuff. '), ('./static/6.mp4', 131, u'Um, I mean that is something that I actually feel '), ('./static/6.mp4', 134, u'a bit awkward about the way things were merged with CS224N, '), ('./static/6.mp4', 138, u'with this deep learning, '), ('./static/6.mp4', 140, u'I mean the truth of the matter is that sort of seems '), ('./static/6.mp4', 142, u'like in the early part of the course, '), ('./static/6.mp4', 144, u"there's so much to cover with, "), ('./static/6.mp4', 147, u'um, neural networks, backpropagation, '), ('./static/6.mp4', 149, u'different, um, neural net architectures and so on that the reality is that we '), ('./static/6.mp4', 154, u'teach rather less linguistic stuff than we used to in the class. '), ('./static/6.mp4', 159, u'I mean, for the last four weeks of the class we really do try and '), ('./static/6.mp4', 163, u'cover some more linguistic stuff topics. '), ('./static/6.mp4', 166, u'Um, so look forward to that. '), ('./static/6.mp4', 169, u'Um, announcements. '), ('./static/6.mp4', 171, u"Okay. So we've made a couple of deadline changes. "), ('./static/6.mp4', 174, u'Um, firstly, a number of people have '), ('./static/6.mp4', 177, u'mentioned that they think assignment five is a bit tough. '), ('./static/6.mp4', 180, u"And so, we're giving people one extra day, "), ('./static/6.mp4', 184, u'um, to do assignment five. '), ('./static/6.mp4', 186, u"Um, I'm realizing in one sense that one extra day is not a ton "), ('./static/6.mp4', 189, u"but you know there's sort of this complex balance here because on the other hand, "), ('./static/6.mp4', 193, u"we don't really want to undermine time that people have available for final projects. "), ('./static/6.mp4', 198, u"And if you're one of the people who hasn't yet started assignment five, "), ('./static/6.mp4', 203, u'um, we do really encourage you to get underway on it. '), ('./static/6.mp4', 206, u'Um, yeah, in the reverse direction '), ('./static/6.mp4', 209, u'we decided that the project milestone was really too late. '), ('./static/6.mp4', 214, u'If we are going to be able to give you feedback on it that you could usefully make use '), ('./static/6.mp4', 218, u"of, so we're moving the project milestone date two days earlier. "), ('./static/6.mp4', 222, u"And so, we've also gotten everyone's project proposals and our "), ('./static/6.mp4', 225, u'planned hope is to get them back to everybody on Friday. '), ('./static/6.mp4', 230, u'Yes, so, a lot of things moving. '), ('./static/6.mp4', 232, u'Um, and finally on other announcements I guess, um, on '), ('./static/6.mp4', 236, u'this Thursday is our first invited speaker, um, and so, '), ('./static/6.mp4', 241, u"if you're in person student you're meant to be here, "), ('./static/6.mp4', 245, u"um, and if you're not able to be here, "), ('./static/6.mp4', 248, u'you should know about our reaction paragraph policy and '), ('./static/6.mp4', 252, u'I actually stuck up on the Piazza pinned posts about, um, '), ('./static/6.mp4', 256, u'reaction pieces and attendance, an example of a reaction piece, um, '), ('./static/6.mp4', 261, u"from a past class to make it a little bit more concrete what's expected there. "), ('./static/6.mp4', 267, u"But, you know, the idea is what we're hoping for something that isn't a ton of work. "), ('./static/6.mp4', 271, u'You can just write 100, 150 words, a few sentences, '), ('./static/6.mp4', 275, u'but wanting you to pick out a specific thing that was '), ('./static/6.mp4', 280, u'interesting and write a couple of sentences '), ('./static/6.mp4', 282, u'about what it was and what your thoughts are about it. '), ('./static/6.mp4', 285, u'I, not just some very generic statement of this was a lecture about transformers. '), ('./static/6.mp4', 290, u'He talked about transformers and it was interesting, '), ('./static/6.mp4', 292, u'that is not what we want for the reaction piece. Um, okay. '), ('./static/6.mp4', 298, u"So, here's the plan for today. "), ('./static/6.mp4', 301, u"So, for today's, what I want to talk about is, "), ('./static/6.mp4', 304, u'um, the exciting recent work about contextual word representations. '), ('./static/6.mp4', 309, u'I mean I, I was thinking of what I was gonna say I was wanting to say, oh, this is '), ('./static/6.mp4', 315, u'the most exciting thing in deep learning for NLP in '), ('./static/6.mp4', 318, u"the last five years then something's just completely wrong, "), ('./static/6.mp4', 322, u'because really this is the most exciting thing in deep learning that happened in 2018. '), ('./static/6.mp4', 327, u'I mean, I guess things move very quickly, um, '), ('./static/6.mp4', 329, u"in deep learning at the moment and it's sort of I don't think it's "), ('./static/6.mp4', 333, u"really fair to say that you know it's got 5 years of life. "), ('./static/6.mp4', 338, u"But there's a very exciting thing that happened last year, "), ('./static/6.mp4', 340, u"and we'll talk about that. "), ('./static/6.mp4', 342, u"Okay. So, we'll talk about early stuff, "), ('./static/6.mp4', 345, u'the ELMo, ULMfit, '), ('./static/6.mp4', 347, u'transformer architectures briefly and then go on to '), ('./static/6.mp4', 350, u"talk about the BERT model that's being quite prominent lately. "), ('./static/6.mp4', 355, u"So, let's just recap, "), ('./static/6.mp4', 358, u"let's just go backwards a bit first to think about, um, "), ('./static/6.mp4', 362, u"where we've been and where we are now and why we might want something more. "), ('./static/6.mp4', 368, u'So, up until now, '), ('./static/6.mp4', 369, u"we've sort of just had, "), ('./static/6.mp4', 371, u'one representation for words which is what we learned at the beginning of class, '), ('./static/6.mp4', 376, u"there was a word, you trained a word vector for it and that's what you used in your model. "), ('./static/6.mp4', 382, u'Um, and you could do that, with algorithms like Word2vec, '), ('./static/6.mp4', 384, u'GloVe, or fastText that I mentioned last week. '), ('./static/6.mp4', 388, u'Um, so some on this sort of progression of ideas in deep learning, '), ('./static/6.mp4', 394, u'when deep learning for NLP or the general '), ('./static/6.mp4', 399, u'just the resurgence of neural networks for NLP '), ('./static/6.mp4', 402, u'came about sort of at the beginning of this decade. '), ('./static/6.mp4', 405, u'Um, these pre-trained word vectors. '), ('./static/6.mp4', 410, u'So, pre-trained unsupervised over a large amount of text. '), ('./static/6.mp4', 414, u'They were completely seen as the secret sauce, '), ('./static/6.mp4', 418, u'and they were the thing that transformed '), ('./static/6.mp4', 420, u"neural networks from NLP to something that didn't really work, "), ('./static/6.mp4', 424, u'to something that worked great. '), ('./static/6.mp4', 426, u'Um, so, this is actually an old slide of mine. '), ('./static/6.mp4', 429, u'So, this is a slide I guess I first made for '), ('./static/6.mp4', 432, u'2012 ACL tutorial and then sort of used in lectures. '), ('./static/6.mp4', 438, u'Sort of in 2013, 2014. Um-. '), ('./static/6.mp4', 442, u'And so this was sort of the picture in those years. '), ('./static/6.mp4', 446, u'So this was looking at two tasks, '), ('./static/6.mp4', 448, u"part of speech tagging and named entity recognition which I'll use quite a bit today. "), ('./static/6.mp4', 453, u'And, you know, the top line was showing a state of the art which was '), ('./static/6.mp4', 458, u'a traditional categorical feature based classifier of the kind '), ('./static/6.mp4', 462, u'that dominated NLP in the 2000s decade, in their performance. '), ('./static/6.mp4', 467, u'And what then the next line showed is that if you took the same data set '), ('./static/6.mp4', 473, u'and you trained a supervised neural network on it and said how good is your performance? '), ('./static/6.mp4', 479, u"Um, the story was, it wasn't great. "), ('./static/6.mp4', 481, u'Um, part-of-speech tagging has very high numbers always for various reasons. '), ('./static/6.mp4', 486, u'So perhaps the more indicative one to look at is these named entity recognition numbers. '), ('./static/6.mp4', 491, u'So, you know, this was sort of neural net sucked, right? '), ('./static/6.mp4', 494, u'The reason why last decade everybody used, um, '), ('./static/6.mp4', 498, u'categorical feature based, you know, '), ('./static/6.mp4', 500, u'CRF, SVM kind of classifiers. '), ('./static/6.mp4', 503, u'Well, if you look, it worked eight percent better than a neural network. '), ('./static/6.mp4', 506, u"Why wouldn't anybody? "), ('./static/6.mp4', 508, u'But then what had happened was people had come up with this idea that we could '), ('./static/6.mp4', 512, u'do unsupervised pre-training of word representations, '), ('./static/6.mp4', 517, u'um, to come up with word vectors for words. '), ('./static/6.mp4', 520, u'And, you know, in those days, '), ('./static/6.mp4', 522, u'this was very hard to do the alg- both because of '), ('./static/6.mp4', 525, u'the kind of algorithms and the kind of machines that were available, right? '), ('./static/6.mp4', 529, u'So Collobert and Weston, 2011, '), ('./static/6.mp4', 531, u'spent seven weeks training their unsupervised word representations. '), ('./static/6.mp4', 536, u'And at the end of the day, '), ('./static/6.mp4', 538, u'there are only 100 dimensional, um, word representations. '), ('./static/6.mp4', 541, u'But this was the miracle breakthrough, right? '), ('./static/6.mp4', 543, u"You've put in this miracle breakthrough of unsupervised word representations. "), ('./static/6.mp4', 548, u'And now, the neural net is getting to 88.87. '), ('./static/6.mp4', 552, u"So it's almost as good as the feature-based classifier, "), ('./static/6.mp4', 555, u'and then like any good engineers, '), ('./static/6.mp4', 557, u'they did some hacking with some extra features, '), ('./static/6.mp4', 559, u'because they had some stuff like that. '), ('./static/6.mp4', 561, u'And they got a system that was then slightly better than the feature based system. '), ('./static/6.mp4', 566, u'Okay. So that was sort of our picture that, '), ('./static/6.mp4', 569, u'um, having these pre-trained, '), ('./static/6.mp4', 573, u'unsuper- and unsupervised manner of word representations, '), ('./static/6.mp4', 576, u'that was sort of the big breakthrough and '), ('./static/6.mp4', 579, u'the secret sauce that gave all the oomph that made, '), ('./static/6.mp4', 582, u'um, neural networks competitive. '), ('./static/6.mp4', 584, u'Um, but, you know, '), ('./static/6.mp4', 586, u"it's a sort of a funny thing happened which was after people had sort of had "), ('./static/6.mp4', 591, u'some of these initial breakthroughs which were '), ('./static/6.mp4', 594, u'all about unsupervised methods for pre-training, '), ('./static/6.mp4', 597, u'it was the same in vision. '), ('./static/6.mp4', 599, u'This was the era in vision, '), ('./static/6.mp4', 600, u'where you were building restricted Boltzmann machines and doing '), ('./static/6.mp4', 603, u'complicated unsupervised pre-training techniques on them as well. '), ('./static/6.mp4', 607, u'Some- somehow, after people had kind of discovered that and started to get good on it, '), ('./static/6.mp4', 613, u'people sort of started to discover, well, '), ('./static/6.mp4', 616, u'actually we have some new technologies for non-linearities, '), ('./static/6.mp4', 620, u'regularization, and things like that. '), ('./static/6.mp4', 622, u'And if we keep using those same technologies, '), ('./static/6.mp4', 625, u'we can just go back to good old supervised learning. '), ('./static/6.mp4', 629, u'And shockingly, it works way better now inside neural networks. '), ('./static/6.mp4', 634, u'And so if you sort of go ahead to what I will call, '), ('./static/6.mp4', 637, u'sort of 2014 to 2018 picture, '), ('./static/6.mp4', 643, u'the, the picture is actually very different. '), ('./static/6.mp4', 646, u'So the picture is, so this, '), ('./static/6.mp4', 648, u"the results I'm actually gonna show you this is from the Chen and Manning, "), ('./static/6.mp4', 651, u'um, neural dependency parser that we talked about weeks ago. '), ('./static/6.mp4', 654, u'The picture there was, um, '), ('./static/6.mp4', 656, u'and you could- despite the fact that '), ('./static/6.mp4', 659, u'this dependency parser is being trained on a pretty small corpus, '), ('./static/6.mp4', 662, u'a million words of supervised data, '), ('./static/6.mp4', 665, u'you can just initialize it with random word vectors, '), ('./static/6.mp4', 669, u'um, and train a dependency parser. '), ('./static/6.mp4', 671, u'And to a first approximation, '), ('./static/6.mp4', 673, u'it just works fine. '), ('./static/6.mp4', 675, u'You get, get sort of a 90 percent accuracy, '), ('./static/6.mp4', 677, u'E- um, English dependency parser. '), ('./static/6.mp4', 680, u'Now, it is the case that instead, '), ('./static/6.mp4', 683, u'you could use pre-trained word embeddings and you do a bit better. '), ('./static/6.mp4', 687, u'You do about one percent better. '), ('./static/6.mp4', 689, u'And so this was sort of the, '), ('./static/6.mp4', 691, u'the new world order which was yeah, um, '), ('./static/6.mp4', 695, u'these pre-trained unsupervised word embeddings are useful because you can '), ('./static/6.mp4', 700, u'train them from a lot more data and they can know about a much larger vocabulary. '), ('./static/6.mp4', 706, u'That means they are useful. '), ('./static/6.mp4', 708, u'They help with rare words and things like that and they give you a percent, '), ('./static/6.mp4', 711, u"but they're definitely no longer the sort of night and day, "), ('./static/6.mp4', 715, u'uh, thing to make neural networks work that we used to believe. '), ('./static/6.mp4', 719, u"I'm, I'm just gonna deviate here to, "), ('./static/6.mp4', 724, u'from the main narrative to just sort of say, um, '), ('./static/6.mp4', 728, u'one more tip for dealing with unknown words with word vectors, '), ('./static/6.mp4', 733, u"um, just in case it's useful for some people, "), ('./static/6.mp4', 736, u'building question answering systems, right? '), ('./static/6.mp4', 739, u'So, um, so for sort of word vectors on unknown words, you know, '), ('./static/6.mp4', 744, u"the commonest thing historically is you've got your supervised training data, "), ('./static/6.mp4', 749, u'you define a vocab which might be words that occur '), ('./static/6.mp4', 752, u'five times or more in your supervised training data. '), ('./static/6.mp4', 756, u'And you treat everything else as an UNK. '), ('./static/6.mp4', 759, u'And so you also train one vector per UNK. '), ('./static/6.mp4', 762, u'Um, but that has some problems which you have no way to '), ('./static/6.mp4', 766, u'distinguish different UNK words either for identity or meaning. '), ('./static/6.mp4', 771, u'And that tends to be problematic for question answering systems. '), ('./static/6.mp4', 774, u'And so one way to fix that is what we talked about last week, '), ('./static/6.mp4', 778, u'you just say, "Oh, words are made out of characters. '), ('./static/6.mp4', 780, u'I can use character representations to learn word vectors for other words." '), ('./static/6.mp4', 785, u'And you can certainly do that. '), ('./static/6.mp4', 786, u'You might wanna try that. '), ('./static/6.mp4', 788, u'That adds some complexity. '), ('./static/6.mp4', 790, u'Um, but especially for things like question answering systems, '), ('./static/6.mp4', 794, u'there are a couple of other things that you can do '), ('./static/6.mp4', 796, u"that work considerably better and they've been "), ('./static/6.mp4', 798, u'explored in this paper by Dhingra et al., um, from 2017. '), ('./static/6.mp4', 803, u'Um, the first one is to say, well, um, '), ('./static/6.mp4', 806, u'when you at test-time encounter new words, probably your unsupervised word, '), ('./static/6.mp4', 814, u'pre-trained word embeddings have a much bigger vocabulary than your actual system does. '), ('./static/6.mp4', 819, u"So anytime you come across a word that isn't in "), ('./static/6.mp4', 822, u'your vocab but is in the pre-trained word embeddings, '), ('./static/6.mp4', 824, u'just use, get the word vector of that word and start using it. '), ('./static/6.mp4', 828, u"That'll be a much more useful thing to use. "), ('./static/6.mp4', 831, u"And then there's a second possible tip that if you "), ('./static/6.mp4', 833, u"see something that's still an unknown word, "), ('./static/6.mp4', 836, u'rather than treating it as UNK, '), ('./static/6.mp4', 837, u'you just assign it on the spot, '), ('./static/6.mp4', 840, u'a random word vector. '), ('./static/6.mp4', 841, u'And so this has the effect that each word does get a unique identity. '), ('./static/6.mp4', 846, u'Which means if you see the same word in the question, '), ('./static/6.mp4', 849, u'and a potential answer, '), ('./static/6.mp4', 851, u"they will match together beautifully in an accurate way which you're "), ('./static/6.mp4', 854, u'not getting with just UNK matching and those can be kind of useful ideas to try. '), ('./static/6.mp4', 859, u'Okay, end digression. Okay, so up until now, '), ('./static/6.mp4', 865, u'we just sort of had this representation of words, '), ('./static/6.mp4', 868, u'we ran Word2vec and we got a word vector, '), ('./static/6.mp4', 871, u'um, for each word. '), ('./static/6.mp4', 873, u'Um, so, um, that, that was useful. '), ('./static/6.mp4', 877, u"It's worked pretty well. "), ('./static/6.mp4', 879, u'Um, but it had, um, '), ('./static/6.mp4', 881, u'some big problems. So what were the big problems of doing that? '), ('./static/6.mp4', 888, u'The problems when we, '), ('./static/6.mp4', 890, u'of having a word vector in each word, yes. '), ('./static/6.mp4', 893, u'A lot of words have like one spelling, but a whole bunch of meanings. '), ('./static/6.mp4', 896, u'Right, so, a word can have- So, typically, '), ('./static/6.mp4', 900, u'you have one string of letters which has a whole bunch of meanings. '), ('./static/6.mp4', 905, u'So, words have a ton of senses. '), ('./static/6.mp4', 909, u"Um, and yeah, so that's "), ('./static/6.mp4', 911, u"the biggest and most obvious problem that we're "), ('./static/6.mp4', 913, u'collapsing together all the meanings of words. '), ('./static/6.mp4', 915, u'So, we talked about a bit where '), ('./static/6.mp4', 918, u'one solution to that was you could distinguish '), ('./static/6.mp4', 920, u'word senses and to have different word vectors for them. '), ('./static/6.mp4', 923, u'Um, and I then said something about also you could think of '), ('./static/6.mp4', 927, u'this word vector as a sort of a mixture of them and maybe your model could separate it. '), ('./static/6.mp4', 931, u'But it seems like we might want to take that more seriously. '), ('./static/6.mp4', 935, u'And one way, um, '), ('./static/6.mp4', 937, u'that we could take that more seriously is we could start to say, well, '), ('./static/6.mp4', 943, u'really, you know, traditional lists of word senses are themselves a crude approximation. '), ('./static/6.mp4', 950, u'What we actually want to know is the sense of the word inside a particular context of use. '), ('./static/6.mp4', 957, u'And sort of what I mean by that is, you know, '), ('./static/6.mp4', 960, u'we distinguish different senses of a word, right? '), ('./static/6.mp4', 964, u"Say for the word star there's the astronomical sense and "), ('./static/6.mp4', 968, u"there's the Hollywood sense and they're clearly different. "), ('./static/6.mp4', 972, u"But you know, if we then go to this what I'm calling the Hollywood sense, "), ('./static/6.mp4', 976, u'I could then say, well, wait a minute. '), ('./static/6.mp4', 978, u'There are movie stars and there are rock stars, '), ('./static/6.mp4', 981, u'and there, uh, are R&B stars, '), ('./static/6.mp4', 984, u'and there are country stars. '), ('./static/6.mp4', 985, u'Now, all of those different senses, um, '), ('./static/6.mp4', 989, u'in certain contexts, though, one or other of them would be evoked. '), ('./static/6.mp4', 993, u'And so, you know, '), ('./static/6.mp4', 994, u"it's very hard if you're trying to actually enumerate "), ('./static/6.mp4', 996, u'senses of a word as to which ones count as different or the same. '), ('./static/6.mp4', 1000, u"So, it's really you sort of wanna know what a word means in a context. "), ('./static/6.mp4', 1004, u"There's a second limitation of these word vectors which is, "), ('./static/6.mp4', 1010, u"we haven't really talked about and is less obvious, "), ('./static/6.mp4', 1013, u"but it's also something that we might want to fix, and at least one of "), ('./static/6.mp4', 1016, u'the models we discussed today takes some aim at that, '), ('./static/6.mp4', 1020, u'and that is, we just sort of have one vector for a word. '), ('./static/6.mp4', 1024, u'But there are sort of different dimensions of a word. '), ('./static/6.mp4', 1027, u'So, words can have different meanings, '), ('./static/6.mp4', 1030, u'some sort of real semantics or words can have '), ('./static/6.mp4', 1034, u'different syntactic behavior like different parts of speech or grammatical behavior. '), ('./static/6.mp4', 1039, u'So, in some sense, arrive and arrival, '), ('./static/6.mp4', 1043, u'their semantics are almost the same, '), ('./static/6.mp4', 1045, u"but they're different parts of speech. "), ('./static/6.mp4', 1048, u'One is a, um, a verb and one is a noun, '), ('./static/6.mp4', 1052, u'so they can kind of appear in quite different places. '), ('./static/6.mp4', 1055, u"And you know, you'd wanna do different things with them in a dependency parser. "), ('./static/6.mp4', 1059, u'And there are even other dimensions. '), ('./static/6.mp4', 1061, u'So, words also have register and connotation differences. '), ('./static/6.mp4', 1067, u'So, you can probably think of lots of different words for a bathroom, '), ('./static/6.mp4', 1072, u'and a lot of those words all means semantically the same, '), ('./static/6.mp4', 1076, u'but have rather different registers and '), ('./static/6.mp4', 1078, u"connotations as to when they're appropriate to use. "), ('./static/6.mp4', 1081, u'And so, we might want to distinguish words on that basis as well. '), ('./static/6.mp4', 1084, u'And so these are the kinds of soluti- things we want to '), ('./static/6.mp4', 1088, u'solve with our new contextual word embeddings. '), ('./static/6.mp4', 1091, u"Um, so I've said up until now, you know, "), ('./static/6.mp4', 1096, u'oh, we just had these word vectors that we use, '), ('./static/6.mp4', 1101, u'words just had one vector. '), ('./static/6.mp4', 1104, u"Um, but if you actually think about it, maybe that's wrong. "), ('./static/6.mp4', 1109, u'I mean, maybe we never had a problem, or at any rate, we solved it six classes ago. '), ('./static/6.mp4', 1114, u'Because if you remember back, [NOISE] um, '), ('./static/6.mp4', 1116, u'to when we started talking about neural language models, '), ('./static/6.mp4', 1119, u'well, what did a neural language model do? '), ('./static/6.mp4', 1121, u'At the bottom, you fed into it the word vectors. '), ('./static/6.mp4', 1125, u'But then you ran across that one or more recurrent layers, '), ('./static/6.mp4', 1129, u'something like a LSTM layer, '), ('./static/6.mp4', 1131, u'and it was calculating these representations that sit above each word and, '), ('./static/6.mp4', 1137, u'you know, the role of those hidden states is a bit ambivalent. '), ('./static/6.mp4', 1140, u'They are used for prediction. '), ('./static/6.mp4', 1142, u'And they are used for next hidden state and output states and so on. '), ('./static/6.mp4', 1146, u'But in many ways you can think huh, '), ('./static/6.mp4', 1149, u'these representations are actually representations of a word in context. '), ('./static/6.mp4', 1156, u'And if you think about what happened with, uh, '), ('./static/6.mp4', 1158, u'the question answering systems, '), ('./static/6.mp4', 1161, u"that's exactly how they were used, right? "), ('./static/6.mp4', 1163, u"We ran LSTM's backwards and forwards, "), ('./static/6.mp4', 1166, u'over a question in the passage, and then we say, '), ('./static/6.mp4', 1169, u"okay those are a good representation of a word's meaning and context. "), ('./static/6.mp4', 1173, u"Let's start matching them with attention functions et cetera. "), ('./static/6.mp4', 1176, u"So, it sort of seemed like we'd already invented a way to have, "), ('./static/6.mp4', 1181, u'um, context-specific representations of words. '), ('./static/6.mp4', 1187, u'And effectively, you know, '), ('./static/6.mp4', 1190, u'the rest of the content of this lecture is sort of basically no more complex than that. '), ('./static/6.mp4', 1195, u'Um, that it took a while but sort of people woke up and started to notice, huh, '), ('./static/6.mp4', 1202, u"really when you're running any language model, "), ('./static/6.mp4', 1204, u'you generate a context-specific representation of words. '), ('./static/6.mp4', 1208, u'Maybe, if we just took those context-specific '), ('./static/6.mp4', 1211, u"representation of words, they'd be useful for doing other things with them. "), ('./static/6.mp4', 1216, u"And that's sort of, you know, "), ('./static/6.mp4', 1218, u'there are a few more details, '), ('./static/6.mp4', 1219, u"but that's really the summary of the entire of this lecture. "), ('./static/6.mp4', 1223, u'Um, so one of the first things to do that was a paper that Matt Peters wrote in 2017, '), ('./static/6.mp4', 1234, u'um, the year before last. '), ('./static/6.mp4', 1236, u'Um, and this was sort of a predecessor to the sort of modern, um, '), ('./static/6.mp4', 1241, u'versions of, um, these context-sensitive word embeddings. '), ('./static/6.mp4', 1246, u'So, um, together with co-authors, '), ('./static/6.mp4', 1249, u'he came up with a paper called TagLM, '), ('./static/6.mp4', 1253, u'but it essentially already had all the main ideas. '), ('./static/6.mp4', 1256, u'So, what, um, was wanted was okay. '), ('./static/6.mp4', 1261, u'We want to do better at tasks such as named-entity recognition. '), ('./static/6.mp4', 1265, u"And what we'd like to do is know about the meaning of a word in context. "), ('./static/6.mp4', 1270, u"Um, but you know, standardly if we're doing named-entity recognition, "), ('./static/6.mp4', 1274, u'we just train it on half a million words of supervised data. '), ('./static/6.mp4', 1278, u"And that's not much of a source of "), ('./static/6.mp4', 1280, u'information to be learning about the meaning of words and context. '), ('./static/6.mp4', 1283, u"So, why don't we adopt the semi-supervised approach and so that's what we do. "), ('./static/6.mp4', 1288, u'So, we start off with a ton of unlabeled data. '), ('./static/6.mp4', 1292, u'Um, and from that unlabeled data, '), ('./static/6.mp4', 1295, u'we can train a conventional word embedding model like Word2vec. '), ('./static/6.mp4', 1299, u'But we can also at the same time train a neural language model. '), ('./static/6.mp4', 1303, u'So, something like a bi-LSTM language model. '), ('./static/6.mp4', 1307, u"Okay. So, then for step two when we're using our supervised data, "), ('./static/6.mp4', 1315, u"um, actually, I guess that's step three. "), ('./static/6.mp4', 1318, u'Okay. Um, so for then when we want to learn our supervised part-of-speech tagger at the top, '), ('./static/6.mp4', 1325, u"what we're gonna do is say, well, "), ('./static/6.mp4', 1329, u'for the input words New what York is located, '), ('./static/6.mp4', 1333, u'we can not only use the word embedding which is context independent, '), ('./static/6.mp4', 1338, u'but we can use our trained recurrent language model and also run it over this import, '), ('./static/6.mp4', 1344, u"and then we'll generate hidden states in our bi-LSTM language model and we can also "), ('./static/6.mp4', 1351, u'feed those in as features into ou- our sequence tagging model, '), ('./static/6.mp4', 1358, u'and those features will let it work better. '), ('./static/6.mp4', 1361, u"Here's a second picture that runs this through in much greater detail. "), ('./static/6.mp4', 1367, u"So, so, we're assuming that we have trained, uh, "), ('./static/6.mp4', 1372, u'bi-LSTM language model, um, '), ('./static/6.mp4', 1376, u'on a lot of unsupervised data. '), ('./static/6.mp4', 1379, u'Then what we wanna do is we want to do named entity recognition for New York is located. '), ('./static/6.mp4', 1386, u'So, the first thing we do is say, '), ('./static/6.mp4', 1389, u"let's just run New York is located through our separately trained neural language model. "), ('./static/6.mp4', 1396, u'So, we run it through a forward language model. '), ('./static/6.mp4', 1398, u'We run it through a backward language model. '), ('./static/6.mp4', 1401, u'We get from that, um, '), ('./static/6.mp4', 1403, u'a hidden state representation, '), ('./static/6.mp4', 1406, u'um, for each word, '), ('./static/6.mp4', 1408, u'we concatenate the forward and backward ones, '), ('./static/6.mp4', 1411, u"and that's going to give a set, a concatenated language model embedding "), ('./static/6.mp4', 1415, u"which we'll use as features in our named entity recognizer. "), ('./static/6.mp4', 1420, u"So, then for the named entity recognizer itself that we're gonna "), ('./static/6.mp4', 1423, u'train supervised while we have the same sentence, '), ('./static/6.mp4', 1428, u'so we can both look up a Word2vec-style token embedding for it. '), ('./static/6.mp4', 1435, u'We can use what we learned about with character level CNNs and RNNs and we can build '), ('./static/6.mp4', 1441, u'a character level representation for it which we also '), ('./static/6.mp4', 1444, u'concatenate to have two representations. '), ('./static/6.mp4', 1447, u'So, we feed these representations into a bi-LSTM layer. '), ('./static/6.mp4', 1455, u'But then when we get the output of the, this bi-LSTM layer, '), ('./static/6.mp4', 1459, u'as well as this normal output, '), ('./static/6.mp4', 1462, u'we can concatenate with each output what was- what we get from our, '), ('./static/6.mp4', 1468, u'um, neural language model. '), ('./static/6.mp4', 1470, u'So, each of these things becomes a pair of states. '), ('./static/6.mp4', 1473, u"One that's spit up from the first bi-LSTM layer and "), ('./static/6.mp4', 1476, u"then it's concatenated with something from the neural language model. "), ('./static/6.mp4', 1479, u'And so that concatenated representation is then fed into a second layer of bi-LSTM. '), ('./static/6.mp4', 1486, u'And then from the output of that, '), ('./static/6.mp4', 1488, u'we do the usual kind of softmax classification '), ('./static/6.mp4', 1491, u"where we're then giving tags like beginning of location, "), ('./static/6.mp4', 1494, u"end of location, say New York is a location and then is, we'll get "), ('./static/6.mp4', 1499, u"another tag to say it's not a location. Does that makes sense? "), ('./static/6.mp4', 1507, u'Yeah so, um, so the central thing is '), ('./static/6.mp4', 1514, u'sort of having seen that these sort of representations that we get from Bi-LSTMs are useful. '), ('./static/6.mp4', 1520, u"We're just going to feed them into supervised models as we train them, "), ('./static/6.mp4', 1524, u'and the idea is that will give us better features of words. '), ('./static/6.mp4', 1528, u'Some kind of representation of their meaning and context, '), ('./static/6.mp4', 1532, u'which will allow us to learn better named entity recognizers or what it- whatever it is. '), ('./static/6.mp4', 1539, u'Maybe I should put this slide earlier, '), ('./static/6.mp4', 1542, u'but this slide was meant to remind you what a named entity recognizer is. '), ('./static/6.mp4', 1545, u'I hope you remember that, '), ('./static/6.mp4', 1547, u'something where are we going to find and label '), ('./static/6.mp4', 1550, u'entities for things like person, location, date, organization. '), ('./static/6.mp4', 1554, u'So anyway, doing this worked. '), ('./static/6.mp4', 1557, u"So, here's a little bit of a history. "), ('./static/6.mp4', 1559, u'So the most famous Named Entity Recognition dataset is this CoNLL 2003 dataset, '), ('./static/6.mp4', 1567, u'which actually exists in multiple languages. '), ('./static/6.mp4', 1570, u"But whenever people say CoNLL 2003 and don't mention a language, "), ('./static/6.mp4', 1574, u'they mean the English version of it. '), ('./static/6.mp4', 1577, u"That's the way the world works. "), ('./static/6.mp4', 1580, u'Um, okay so on this dataset- yeah. '), ('./static/6.mp4', 1584, u"So, it's sort of been around for whatever, 15 years roughly now. "), ('./static/6.mp4', 1589, u'So, in the- so it was originally a competition, right? '), ('./static/6.mp4', 1592, u'So, this is in 2003 was the original bake-off. '), ('./static/6.mp4', 1596, u'My group actually took place in that. '), ('./static/6.mp4', 1598, u'Took part in it. I think we got third or fourth place or something, '), ('./static/6.mp4', 1602, u'and our F1 score was 86. '), ('./static/6.mp4', 1606, u'The people who won were from IBM Research Labs, '), ('./static/6.mp4', 1612, u'and they got 88 almost 89. '), ('./static/6.mp4', 1615, u'But a difference between these two things is our system was '), ('./static/6.mp4', 1620, u'a single clean machine-learning model categorical, '), ('./static/6.mp4', 1625, u'whereas the IBM one was not only an ensemble '), ('./static/6.mp4', 1628, u'of four different machine learning models, plus gazetteers. '), ('./static/6.mp4', 1633, u'It also fit in the output of '), ('./static/6.mp4', 1636, u'two other old NER systems that IBM people were trained years ago on different data. '), ('./static/6.mp4', 1642, u'So it was- I guess it worked for them but, '), ('./static/6.mp4', 1645, u'it was a fairly complex system. '), ('./static/6.mp4', 1647, u"Here's another system from Stanford. "), ('./static/6.mp4', 1649, u'So this was our classic Stanford NER system that is widely used. '), ('./static/6.mp4', 1653, u'So, this was then using a conditional random field model which generally dominated '), ('./static/6.mp4', 1659, u'sort of the second half of the 2000s and the first half of the 2010s for doing NER, '), ('./static/6.mp4', 1666, u'and it was sort of, you know, a bit but not usually better than the 2003 system. '), ('./static/6.mp4', 1672, u'This system here was sort of the best ever built categorical CRF system. '), ('./static/6.mp4', 1679, u'But rather than only using the training data to build the model as this system did, '), ('./static/6.mp4', 1686, u'it threw in Wikipedia and other stuff to make it work better, '), ('./static/6.mp4', 1691, u'and that got you to about 90.8 F1. '), ('./static/6.mp4', 1694, u'So, essentially, once sort of BiLSTM style models started to be known and used in NLP. '), ('./static/6.mp4', 1703, u'That was when people were able to train, build training '), ('./static/6.mp4', 1708, u'just on the training data systems that worked a lot better. '), ('./static/6.mp4', 1713, u"Because essentially you're going from the same data from this system to that system. "), ('./static/6.mp4', 1718, u"So, you're getting about 4 percent gain on it, "), ('./static/6.mp4', 1721, u"because it's not- wasn't making use of Wikipedia and things like that; "), ('./static/6.mp4', 1725, u'and so this Ma and Hovy system is pretty well-known getting about 91.21. '), ('./static/6.mp4', 1731, u'Okay, but if we then go to this TagLM system, um, '), ('./static/6.mp4', 1736, u'that Matt Peters and Co have a system that '), ('./static/6.mp4', 1740, u'was sort of similar to the Ma and Hovy system that is a little bit worse. '), ('./static/6.mp4', 1745, u'But the point is that this BiLSTM uses sorry- using the neural language model, '), ('./static/6.mp4', 1752, u'is just a useful oomph giver which sort of takes the results up. '), ('./static/6.mp4', 1757, u'Yeah, not night and day but, '), ('./static/6.mp4', 1758, u'slightly over a percent and then gives them the best NER system that was then available. '), ('./static/6.mp4', 1764, u'So that sort of proved these sort of '), ('./static/6.mp4', 1765, u'contextual word representations really had some power and started to be useful, '), ('./static/6.mp4', 1773, u"and then there's a white space at the top because we'll get back to more of this later. "), ('./static/6.mp4', 1778, u"Um, there's some details on their language model. "), ('./static/6.mp4', 1783, u"Some of their details are that it's useful to have "), ('./static/6.mp4', 1786, u'a bidirectional language model, not unidirectional. '), ('./static/6.mp4', 1789, u"It's useful to have a big um, "), ('./static/6.mp4', 1791, u'language model to get much in the way of gains, '), ('./static/6.mp4', 1795, u'um and, you need to train this language model over much more data. '), ('./static/6.mp4', 1801, u"It doesn't work if you're just sort of training it over your supervised training data. "), ('./static/6.mp4', 1808, u'Another model that was around was CoVe, '), ('./static/6.mp4', 1811, u"but I think I'll skip that. "), ('./static/6.mp4', 1812, u'Okay. So, then the next year, um, '), ('./static/6.mp4', 1815, u'Matt Peters and a different set of colleagues '), ('./static/6.mp4', 1818, u'then came up with an improved system called ELMo, '), ('./static/6.mp4', 1823, u'and effectively this was the breakthrough system. '), ('./static/6.mp4', 1827, u'That this was sort of just the system that everybody '), ('./static/6.mp4', 1830, u'noticed and said "Wow these contextual word vectors are great. '), ('./static/6.mp4', 1835, u'Everyone should be using them, '), ('./static/6.mp4', 1837, u'not traditional word vectors." Yes? '), ('./static/6.mp4', 1841, u'I have a simple question, imagine re-training a system, what exactly '), ('./static/6.mp4', 1859, u'what measure [inaudible] '), ('./static/6.mp4', 1862, u"It's pre-trained because this piece over here; "), ('./static/6.mp4', 1866, u'a big neural language model is trained first, '), ('./static/6.mp4', 1871, u"and there's an important thing I forgot to say. "), ('./static/6.mp4', 1873, u'So, thank you for the question. '), ('./static/6.mp4', 1875, u"The main reason why it's- in some sense pre-trained, "), ('./static/6.mp4', 1880, u'is this was trained first. '), ('./static/6.mp4', 1881, u'But the main reason why people think of this as pre-training '), ('./static/6.mp4', 1886, u"is after you've trained this, it is frozen. "), ('./static/6.mp4', 1890, u'So, this is just something that you can run with parameters which will give '), ('./static/6.mp4', 1895, u'you a vector which is your contextual word representation each position, '), ('./static/6.mp4', 1900, u"and then that's just going to be used in this system. "), ('./static/6.mp4', 1903, u"So, when you're training this system, "), ('./static/6.mp4', 1906, u"there's no gradient flowing back into "), ('./static/6.mp4', 1908, u"this neural language model that's changing and updating it; it's just fixed. "), ('./static/6.mp4', 1912, u"And so that's sort of the sense when people are talking about pre-training. "), ('./static/6.mp4', 1916, u"It's sort of normally a model that you trained "), ('./static/6.mp4', 1919, u"somewhere else and that you're using to give features, "), ('./static/6.mp4', 1922, u"but isn't part of the model that you are now training. Yeah? "), ('./static/6.mp4', 1926, u'[inaudible] '), ('./static/6.mp4', 1932, u"Well, I guess that's, I wouldn't quite call it reconstruction. "), ('./static/6.mp4', 1936, u"Yeah, it's unsupervised in the sense that this is a language model, "), ('./static/6.mp4', 1940, u"you're training it to predict the next word. "), ('./static/6.mp4', 1942, u'So here are words one to k. What is the k plus oneth word during a cross entropy loss, '), ('./static/6.mp4', 1948, u'and repeat over for each position. '), ('./static/6.mp4', 1950, u'[NOISE] Yes, so I mean, '), ('./static/6.mp4', 1957, u'having gone through TagLM in some detail, I mean, '), ('./static/6.mp4', 1965, u'in some sense, the difference between TagLM and ELMo is kind of small, '), ('./static/6.mp4', 1972, u"it's sort of in the details. "), ('./static/6.mp4', 1974, u'So I mean, to a first approximation, '), ('./static/6.mp4', 1976, u"they're doing exactly the same again, "), ('./static/6.mp4', 1978, u'but a little bit better. '), ('./static/6.mp4', 1980, u'Um, so, um, I sort of hope it made sense the last time, '), ('./static/6.mp4', 1986, u'I mean, what are the things that are different? '), ('./static/6.mp4', 1989, u'Um, they do the bidirectional language model a bit differently, '), ('./static/6.mp4', 1993, u'and actually one of their concerns was to try and come up with '), ('./static/6.mp4', 1996, u'a compact language model that would be easy for people to use, '), ('./static/6.mp4', 2001, u"um, in other tasks even if they don't have the beefiest computer hardware in the world. "), ('./static/6.mp4', 2007, u'And so they decided to dispense with having '), ('./static/6.mp4', 2009, u'word representations altogether and just use, um, '), ('./static/6.mp4', 2014, u'character CNNs to build word representations, '), ('./static/6.mp4', 2018, u'because that lessens the number of parameters you have to store, '), ('./static/6.mp4', 2022, u'the big matrices you have to, um, use. '), ('./static/6.mp4', 2025, u'Um, they expanded the hidden dimension to 4,096, '), ('./static/6.mp4', 2030, u'but then they project it down to '), ('./static/6.mp4', 2032, u'512 dimensions with a sort of feed-forward projection layer, '), ('./static/6.mp4', 2037, u"and that's a fairly common technique to again reduce "), ('./static/6.mp4', 2040, u'the parameterization of the model so that you have a lot of '), ('./static/6.mp4', 2043, u'parameters going in their current direction but you '), ('./static/6.mp4', 2046, u'need much smaller matrices for including, '), ('./static/6.mp4', 2049, u'um, the input at the next level. '), ('./static/6.mp4', 2051, u'Um, between the layers, '), ('./static/6.mp4', 2053, u'they now use a residual connection and they do a bit of parameter tying. '), ('./static/6.mp4', 2058, u"So it's sort of all in the little details there. "), ('./static/6.mp4', 2061, u"Um, but there's another interesting thing "), ('./static/6.mp4', 2065, u'that they did which was an important innovation of ELMo, '), ('./static/6.mp4', 2068, u'so we should get this bit. '), ('./static/6.mp4', 2070, u'So in TagLM, '), ('./static/6.mp4', 2072, u'what was fed from the pre-trained LM into '), ('./static/6.mp4', 2076, u'the main model was just the top level of the neural language model stack, '), ('./static/6.mp4', 2083, u'and that was completely standard de rigueur in those days, '), ('./static/6.mp4', 2087, u'that you might have had three layers of '), ('./static/6.mp4', 2089, u'neural language model that you regard at the top-level as your sort '), ('./static/6.mp4', 2093, u"of one that's really captured the meaning of "), ('./static/6.mp4', 2097, u'the sentence and the lower layers for processing that led up to it. '), ('./static/6.mp4', 2101, u'Um, and they had the idea that maybe '), ('./static/6.mp4', 2105, u'it would be useful to actually use all layers of the, '), ('./static/6.mp4', 2109, u'biLSTM of the neural language models. '), ('./static/6.mp4', 2112, u'So maybe not just the top layer but all layers would be kind of useful. '), ('./static/6.mp4', 2116, u'So, um, there are these kind of complex equations, '), ('./static/6.mp4', 2120, u'uh, but essentially the point of it over here is, '), ('./static/6.mp4', 2124, u'we going- for a particular position, '), ('./static/6.mp4', 2127, u'word seven in the language model, '), ('./static/6.mp4', 2129, u"we're going to take the hidden state at each level of our, "), ('./static/6.mp4', 2133, u'our neural language model stack, '), ('./static/6.mp4', 2136, u"we're going to give- learn a weight for that level, "), ('./static/6.mp4', 2140, u'we go in to sort of sum them, '), ('./static/6.mp4', 2142, u'so this is sort of a weighted average of the hidden layers at each position, '), ('./static/6.mp4', 2147, u'and that will be used as our basic representation. '), ('./static/6.mp4', 2151, u'Um, and so, they found that that gave quite a bit '), ('./static/6.mp4', 2155, u'of extra usefulness for- and different tasks could prefer different layers. '), ('./static/6.mp4', 2160, u"There's one other bit here which is, "), ('./static/6.mp4', 2163, u'they learn a global scaling factor Gamma for a particular task. '), ('./static/6.mp4', 2168, u'And this allows them to control that for some tasks, the, um, '), ('./static/6.mp4', 2173, u'contextual word embeddings might be really '), ('./static/6.mp4', 2176, u'useful and for other tasks they might not be so useful, '), ('./static/6.mp4', 2179, u"so you're just sort of learning a specific, "), ('./static/6.mp4', 2181, u'um, usefulness for the entire task. '), ('./static/6.mp4', 2185, u"Okay. So, um, that's the sort of new version of language model. "), ('./static/6.mp4', 2190, u'But this, this is allowing this idea of well, '), ('./static/6.mp4', 2193, u"maybe there's sort of more syntactic meanings "), ('./static/6.mp4', 2196, u'of a word and more semantic meanings of a word, '), ('./static/6.mp4', 2199, u'possibly those could be represented at different layers of '), ('./static/6.mp4', 2203, u'your neural language model and then for '), ('./static/6.mp4', 2205, u'different tasks you can differentially weight them. '), ('./static/6.mp4', 2208, u"Um, so that's the basic model. "), ('./static/6.mp4', 2211, u'So you run your biLSTM before to g et representations of each word. '), ('./static/6.mp4', 2216, u'And then the generic ELMo recipe was, '), ('./static/6.mp4', 2219, u'well, with that frozen language model, '), ('./static/6.mp4', 2223, u'you want to feed it into some supervised model depending on what the task was, '), ('./static/6.mp4', 2228, u'and they sort of say in the paper, well, '), ('./static/6.mp4', 2230, u'how you do this maybe depends on the task. '), ('./static/6.mp4', 2232, u'You might want to kind of concatenate it to the intermediate layer, '), ('./static/6.mp4', 2235, u'just as the TagLM did, '), ('./static/6.mp4', 2237, u'that might be fine. '), ('./static/6.mp4', 2239, u'But you know it might also be useful to make use of '), ('./static/6.mp4', 2242, u'these ELMo representations when producing outputs, '), ('./static/6.mp4', 2245, u"so if you're doing something like a "), ('./static/6.mp4', 2248, u'generation system or you might just sort of feed in the ELMo representation again, '), ('./static/6.mp4', 2255, u'be- before you sort of do the softmax to find the output, '), ('./static/6.mp4', 2258, u'they sort of left it flexible as to how it was used, '), ('./static/6.mp4', 2261, u'but the general picture, '), ('./static/6.mp4', 2262, u'you know, was kinda like we saw before. '), ('./static/6.mp4', 2265, u"Indeed I'm reusing the same picture that you've calculated "), ('./static/6.mp4', 2269, u'an ELMo representation for each position as a weighted average, '), ('./static/6.mp4', 2274, u"and then you're sort of concatenating that to the hidden state of "), ('./static/6.mp4', 2277, u'your supervised system and generating your output. '), ('./static/6.mp4', 2281, u'And anyway, um, one way or another, '), ('./static/6.mp4', 2284, u'um, they were able to do this, uh, '), ('./static/6.mp4', 2287, u'and that with the little improvements that gave them about an extra '), ('./static/6.mp4', 2291, u'0.3 percent in Named Entity Recognition. '), ('./static/6.mp4', 2296, u'Um, now, that sort of sounds like not very much. '), ('./static/6.mp4', 2301, u'And you might conclude from this why the excitement [LAUGHTER] and, '), ('./static/6.mp4', 2306, u'you know, in some sense, um, '), ('./static/6.mp4', 2308, u"that's right because sort of to the extent that there was an interesting idea here really "), ('./static/6.mp4', 2313, u'that come up with it for the TagLM paper which gave a much better gain. '), ('./static/6.mp4', 2319, u'But, you know, why everyone got really excited was that in the ELMo paper, '), ('./static/6.mp4', 2325, u"they then showed this isn't something that you can "), ('./static/6.mp4', 2328, u'do one-off to improve a Named Entity Recognizer, '), ('./static/6.mp4', 2330, u'you can take these ELMo representations and use them for pretty much any NLP task, '), ('./static/6.mp4', 2338, u'and they can be very useful and give good gains. '), ('./static/6.mp4', 2341, u"And so, essentially why people got excited was because of the data that's in this table. "), ('./static/6.mp4', 2348, u"So here we're taking a whole bunch of very different tasks, "), ('./static/6.mp4', 2351, u"so there's SQuAD question-answering, uh, "), ('./static/6.mp4', 2353, u"there's natural language inference, "), ('./static/6.mp4', 2356, u"there's semantic role labeling, "), ('./static/6.mp4', 2358, u"there's co-reference, the Named Entity Recognition, doing sentiment analysis, "), ('./static/6.mp4', 2363, u'so a wide range of different NLP tasks, '), ('./static/6.mp4', 2366, u'and they have a previous state of the art system. '), ('./static/6.mp4', 2370, u'They produced their own baseline um, which is, '), ('./static/6.mp4', 2374, u'you know, commonly sort of similar to the previous state of the art, '), ('./static/6.mp4', 2380, u'but usually actually a bit worse than '), ('./static/6.mp4', 2383, u"the current state of the art because it's "), ('./static/6.mp4', 2385, u'whatever simpler cleaner system that they came up with, '), ('./static/6.mp4', 2388, u'but then they could say in each case, '), ('./static/6.mp4', 2391, u'oh, just take this system and add '), ('./static/6.mp4', 2395, u'ELMo vectors into the hidden representations in the middle, '), ('./static/6.mp4', 2399, u'and have those help you predict. '), ('./static/6.mp4', 2402, u'And in general, in all cases, '), ('./static/6.mp4', 2404, u"that's giving you about a three percent or so gain absolute "), ('./static/6.mp4', 2408, u'which was then producing this huge performance increase, '), ('./static/6.mp4', 2413, u'which in all cases was moving the performance well above the previous, '), ('./static/6.mp4', 2418, u'um, state of the art system. '), ('./static/6.mp4', 2420, u'So you know, this sort of then made it seem like magic pixie dust, '), ('./static/6.mp4', 2424, u'because, you know, in the stakes of NLP conference land, you know, '), ('./static/6.mp4', 2428, u'a lot of people use to try and to come up '), ('./static/6.mp4', 2430, u"with a paper for the next year that's one percent better "), ('./static/6.mp4', 2434, u"on one task and writing it up and that's "), ('./static/6.mp4', 2437, u'their big breakthrough for the year to get their new paper out. '), ('./static/6.mp4', 2441, u"And the idea that there's just well this set of "), ('./static/6.mp4', 2444, u'this way of creating context sensitive, um, '), ('./static/6.mp4', 2448, u'word representations and you just use them in any task, '), ('./static/6.mp4', 2451, u"and they'll give you around three percent and take you past the state of the art, "), ('./static/6.mp4', 2455, u'this seemed like it was really great stuff. '), ('./static/6.mp4', 2458, u'And so people got very excited about this and that won '), ('./static/6.mp4', 2461, u'the Best Paper Award at the NAACL 2018 conference. '), ('./static/6.mp4', 2466, u'Ah, and then, a- as I sort of vaguely mentioned, '), ('./static/6.mp4', 2470, u"um, so the model that they actually used wasn't a deep stack, "), ('./static/6.mp4', 2474, u'there were actually only two layers of biLSTMs, '), ('./static/6.mp4', 2477, u'but they do show this interesting result that the lower level better captures '), ('./static/6.mp4', 2482, u'low-level syntax word properties '), ('./static/6.mp4', 2486, u'and its most useful things like part-of-speech tagging,  syntactic '), ('./static/6.mp4', 2490, u'dependencies, NER, where the top layer of '), ('./static/6.mp4', 2493, u'their language model is better for '), ('./static/6.mp4', 2495, u'higher level semantics that is more useful for things like sentiments, '), ('./static/6.mp4', 2498, u'semantic role labeling and question answering. '), ('./static/6.mp4', 2502, u'Um, so that seemed interesting, '), ('./static/6.mp4', 2505, u"though it'll actually be interesting to see how that panned "), ('./static/6.mp4', 2507, u'out more if you had sort of more layers to play with. '), ('./static/6.mp4', 2512, u'Okay. ELMo, done. '), ('./static/6.mp4', 2515, u"Um, so I'm moving right ahead. "), ('./static/6.mp4', 2518, u"Um, here's something else that I just thought I should mention a little bit about, "), ('./static/6.mp4', 2525, u'another piece of work that came out around the same time, '), ('./static/6.mp4', 2529, u'a few months later maybe or maybe not, '), ('./static/6.mp4', 2532, u'came out around the same time, uh, '), ('./static/6.mp4', 2534, u'in, in 2018, was this work on '), ('./static/6.mp4', 2538, u'Universal Language Model Fine-tuning for text classification, '), ('./static/6.mp4', 2543, u'um, or ULMfit, by Howard and Ruder. '), ('./static/6.mp4', 2545, u'And essentially this had the same general idea of saying, Well, '), ('./static/6.mp4', 2551, u'what we want to do is transfer learning where we could learn a big language model, um. '), ('./static/6.mp4', 2560, u'A big language model, '), ('./static/6.mp4', 2563, u'and then for our target task which might be named entity recognition. '), ('./static/6.mp4', 2568, u"But here's text classification, "), ('./static/6.mp4', 2570, u'we can transfer this language model information and help us to do better with the task. '), ('./static/6.mp4', 2575, u'And so, they proposed an architecture to do that. '), ('./static/6.mp4', 2578, u'And so, their architecture was, '), ('./static/6.mp4', 2580, u'you have a big unsupervised corpus from which you train a neural language model. '), ('./static/6.mp4', 2587, u'They used the deeper neural language model with three hidden layers. '), ('./static/6.mp4', 2592, u'Um, you then fine tune '), ('./static/6.mp4', 2594, u"your neural language model on the actual domain that you're interested in working in. "), ('./static/6.mp4', 2599, u'So, this was sort of an extra stage that they did. '), ('./static/6.mp4', 2602, u'And then finally, um, '), ('./static/6.mp4', 2604, u'you now introduce your classification objectives. '), ('./static/6.mp4', 2608, u"So, what they're going to be doing is making text classifiers. "), ('./static/6.mp4', 2611, u"So, we're now wanting to, "), ('./static/6.mp4', 2613, u'take this model and turn it from a language model into a text classifier. '), ('./static/6.mp4', 2619, u"Um, but there's something that they did differently, um, "), ('./static/6.mp4', 2622, u'which is in some sense, '), ('./static/6.mp4', 2623, u'foreshadows the later work in transformers. '), ('./static/6.mp4', 2626, u'So, rather than just feeding features from this into a completely different network, '), ('./static/6.mp4', 2632, u'they keep using the same network but they introduce a different objective at the top. '), ('./static/6.mp4', 2638, u'So, one thing you could do with this network is use '), ('./static/6.mp4', 2641, u'it to predict the next word as a language model. '), ('./static/6.mp4', 2645, u'And so at this point, '), ('./static/6.mp4', 2646, u'they freeze the parameters of that softmax at the top, '), ('./static/6.mp4', 2649, u"that's why it's shown in black. "), ('./static/6.mp4', 2651, u'Um, but instead, they could stick on '), ('./static/6.mp4', 2654, u"a different prediction unit where it's predicting stuff for a particular task. "), ('./static/6.mp4', 2659, u'So, it might be predicting '), ('./static/6.mp4', 2661, u'positive or negative sentiment in a text classification task or something like that. '), ('./static/6.mp4', 2666, u'So, in their model, '), ('./static/6.mp4', 2667, u"they're sort of reusing the same network but sticking on the top of that, "), ('./static/6.mp4', 2671, u'a different layer, to do the new classification task. '), ('./static/6.mp4', 2676, u'Um, they were also interested in something small, '), ('./static/6.mp4', 2679, u'the sort of one GPU model of research, um, '), ('./static/6.mp4', 2683, u'the paper has a lot of detail, the sort of tricks '), ('./static/6.mp4', 2687, u'and care and feeding of your neural models to maximize performance. '), ('./static/6.mp4', 2692, u"If you're interested in that, you could sort of look up some of the details about that. "), ('./static/6.mp4', 2696, u'Um, but what they were able to show again, '), ('./static/6.mp4', 2700, u'was making use of this language model pre-training was '), ('./static/6.mp4', 2703, u'a very effective way to improve performance, '), ('./static/6.mp4', 2707, u'this time for text classification. '), ('./static/6.mp4', 2709, u'So, these are text classification datasets, '), ('./static/6.mp4', 2712, u'IMDb is for sentiment, '), ('./static/6.mp4', 2714, u'um, TREC is for topical text classification, and again, '), ('./static/6.mp4', 2718, u'there are preceding systems that other people have developed and they '), ('./static/6.mp4', 2722, u'are showing that by making use of this language model pre-training, '), ('./static/6.mp4', 2726, u"they're able to significantly improve on the state of the art of these error rates, "), ('./static/6.mp4', 2731, u'so that low is good. '), ('./static/6.mp4', 2733, u'They also showed another interesting result which is kind of, '), ('./static/6.mp4', 2739, u'um, what you would expect or hope from doing this kind of transfer learning, '), ('./static/6.mp4', 2744, u'that what they were able to show is, '), ('./static/6.mp4', 2746, u'if you can train this neural language model on a big amount of data, '), ('./static/6.mp4', 2751, u'that that means you will then be able to do well on '), ('./static/6.mp4', 2754, u'your supervised task even when trained on pretty little data. '), ('./static/6.mp4', 2759, u'Um, so, here this is error rate, '), ('./static/6.mp4', 2761, u'so low is good. '), ('./static/6.mp4', 2763, u"So, what the- and here's the number of "), ('./static/6.mp4', 2765, u'training examples which has being done on a log scale. '), ('./static/6.mp4', 2768, u"And so the blue line is if you're just training "), ('./static/6.mp4', 2771, u'a text classifier from scratch on supervised data. '), ('./static/6.mp4', 2775, u'So, you need a lot of data to start to do pretty well. '), ('./static/6.mp4', 2779, u"Um, but if you're making use of this transfer learning, um, "), ('./static/6.mp4', 2784, u'from a pre-trained language model, '), ('./static/6.mp4', 2787, u"you can get to that you're sort of doing pretty "), ('./static/6.mp4', 2790, u'well with way less, um, training examples. '), ('./static/6.mp4', 2793, u'Essentially, an order of magnitude, '), ('./static/6.mp4', 2795, u'less training examples will give you the same amount of performance. '), ('./static/6.mp4', 2799, u'And the difference between these two lines corresponds to the extra, '), ('./static/6.mp4', 2804, u'um, phase that they had in the middle of theirs, um, which is, '), ('./static/6.mp4', 2808, u"whether you're doing this sort of extra fine tuning on your target domain, "), ('./static/6.mp4', 2813, u"um, it's part of your process and they found that to be pretty helpful. "), ('./static/6.mp4', 2818, u'Okay. So, that, um, is another precursor. '), ('./static/6.mp4', 2825, u'Um, and so, one big part of what has happened since then, '), ('./static/6.mp4', 2831, u'is effectively people said this is a good idea, uh, '), ('./static/6.mp4', 2835, u"maybe it'll become a really really good idea if we just make things way bigger. "), ('./static/6.mp4', 2841, u'Um, so, ULMfit, um, '), ('./static/6.mp4', 2844, u'was something that you could train in one GPU day, '), ('./static/6.mp4', 2848, u'sounds appealing for CS224N final projects, '), ('./static/6.mp4', 2851, u'remember that, um, and but well, '), ('./static/6.mp4', 2854, u'then the people at OpenAI decided, well, '), ('./static/6.mp4', 2859, u'we could build a pretrain language model and train it on '), ('./static/6.mp4', 2863, u'a much larger amount of data on a much larger amount of compute, '), ('./static/6.mp4', 2867, u'and use about 242 GPU days and that will get a lot better, and it did. '), ('./static/6.mp4', 2874, u'Um, and then the people at Google said, '), ('./static/6.mp4', 2877, u'well we could train a model, um, '), ('./static/6.mp4', 2880, u'in to 256 TPU days, '), ('./static/6.mp4', 2884, u'which means maybe about double the amount of computation. '), ('./static/6.mp4', 2887, u"It's hard to figure out exactly, "), ('./static/6.mp4', 2889, u'and that might be able to do exciting things, '), ('./static/6.mp4', 2892, u'and that was the BERT model, and it did. '), ('./static/6.mp4', 2894, u"Um, and then if you're following along these things, um, "), ('./static/6.mp4', 2898, u'just last week, um, '), ('./static/6.mp4', 2900, u'the OpenAI people said, '), ('./static/6.mp4', 2902, u'well we can go much bigger again and we can train a model, um, '), ('./static/6.mp4', 2906, u'for approximately 2,000 TPU version three days. '), ('./static/6.mp4', 2912, u'Um, and it will be able to, '), ('./static/6.mp4', 2916, u'um, do much bigger again, '), ('./static/6.mp4', 2919, u'a bit much better again, '), ('./static/6.mp4', 2921, u'um, and so, this is this GP2, '), ('./static/6.mp4', 2924, u'GPT-2 language model, um, '), ('./static/6.mp4', 2927, u'which OpenAI released last week. '), ('./static/6.mp4', 2930, u"Um, and they're, they're actually very impressive results, um, "), ('./static/6.mp4', 2936, u"when they're showing that if you're sort of building a really, "), ('./static/6.mp4', 2940, u'really huge language model over a very large amount of data. '), ('./static/6.mp4', 2945, u'And then you say language model go off and generate some text, '), ('./static/6.mp4', 2949, u'on this particular topic, '), ('./static/6.mp4', 2951, u'that it can actually just do a great job of producing text. '), ('./static/6.mp4', 2955, u'So, the way this was being do- done, '), ('./static/6.mp4', 2957, u'was a humanist writing a couple of sentences; '), ('./static/6.mp4', 2959, u'in a shocking finding, '), ('./static/6.mp4', 2961, u'scientists discovered a herd of unicorns, '), ('./static/6.mp4', 2963, u'living in remote previously unexplored valley in the Andes Mountains. '), ('./static/6.mp4', 2967, u'Um, and so, we then, '), ('./static/6.mp4', 2969, u'using our neural language model and chugging through that, '), ('./static/6.mp4', 2973, u'so that gives us context, '), ('./static/6.mp4', 2975, u'and then say generate more text, '), ('./static/6.mp4', 2977, u'and it starts to generate the scientist '), ('./static/6.mp4', 2979, u'named the population after their distinctive horn, '), ('./static/6.mp4', 2982, u"Ovid's Unicorn, these four-horned, "), ('./static/6.mp4', 2984, u'silver-white Uni four corns were previously unknown to science. '), ('./static/6.mp4', 2987, u'Um, it produces remarkably, '), ('./static/6.mp4', 2990, u'um, good text or at least in the, '), ('./static/6.mp4', 2992, u'in the hand-picked examples [LAUGHTER] that they showed in the tech news, '), ('./static/6.mp4', 2997, u'um, it produces extremely good text. '), ('./static/6.mp4', 2999, u'Um, yeah so, I think one should be a little bit cautious about, um, '), ('./static/6.mp4', 3004, u'that and sort of some of its random outputs actually '), ('./static/6.mp4', 3007, u"aren't nearly as good but nevertheless you know, "), ('./static/6.mp4', 3010, u'I think is is actually dramatic '), ('./static/6.mp4', 3012, u'how good language models are becoming once you are training '), ('./static/6.mp4', 3016, u'them on long contexts as we can do with modern models on vast amounts of data, um-. '), ('./static/6.mp4', 3023, u'So then, um, the OpenAI people decided '), ('./static/6.mp4', 3027, u"this language model was so good that they weren't gonna release it to the world, um, "), ('./static/6.mp4', 3031, u'which then got transformed into headlines of, '), ('./static/6.mp4', 3034, u"Elon Musk's OpenAI builds artificial intelligence so powerful, "), ('./static/6.mp4', 3039, u'it must be kept locked up for the good of humanity. '), ('./static/6.mp4', 3041, u'[LAUGHTER] Um, with the suitable pictures that always turn off at '), ('./static/6.mp4', 3046, u'these moments down the bottom of the screen, um, and, '), ('./static/6.mp4', 3052, u'um, yeah I guess that was the leading even Elon Musk to be wanting to clarify and say '), ('./static/6.mp4', 3057, u"that it's not actually really that he's directing what's happening at OpenAI anymore. "), ('./static/6.mp4', 3063, u'Um, anyway, moving right along. '), ('./static/6.mp4', 3066, u'Um, so, part of the story here is '), ('./static/6.mp4', 3069, u'just a scaling thing that these things have been getting bigger and bigger, '), ('./static/6.mp4', 3074, u'um, but the other part of the story is that all three of '), ('./static/6.mp4', 3078, u'these are then systems that use the transformer architecture. '), ('./static/6.mp4', 3083, u'And transformer architectures have not only being very powerful, '), ('./static/6.mp4', 3087, u'but technically had allowed scaling to much bigger sizes. '), ('./static/6.mp4', 3092, u'So to understand some of the rest of these, um, '), ('./static/6.mp4', 3095, u'we should learn more about transformers. '), ('./static/6.mp4', 3099, u"And so, I'm sort of gonna do that, um, "), ('./static/6.mp4', 3102, u'but I mean, um, in mix of orders, '), ('./static/6.mp4', 3106, u'um, our invited speaker coming Thursday uh, is, um, '), ('./static/6.mp4', 3110, u'one of the authors of the transformer paper, '), ('./static/6.mp4', 3112, u"and he's gonna talk about transformers. "), ('./static/6.mp4', 3114, u"So I think what I'm gonna do is, um, "), ('./static/6.mp4', 3117, u'say a little bit about transformers quickly, '), ('./static/6.mp4', 3121, u'but not really dwell on all the details, um, '), ('./static/6.mp4', 3124, u"but hope that it's a bit of an introduction, "), ('./static/6.mp4', 3126, u'and you can find out more on Thursday about the details and '), ('./static/6.mp4', 3130, u'then talk some more about the BERT model before finishing. '), ('./static/6.mp4', 3135, u'So the motivation for transformers is essentially '), ('./static/6.mp4', 3139, u'we want things to go faster so we can build bigger models, '), ('./static/6.mp4', 3143, u'and the problem as we mentioned for these, um, '), ('./static/6.mp4', 3146, u"LSTM or in general any of the recurrent models is the fact that they're recurrent. "), ('./static/6.mp4', 3151, u'You have to generate sort of one to n status time chugging through, '), ('./static/6.mp4', 3156, u"and that means you just can't do the same kind of parallel computation, um, "), ('./static/6.mp4', 3161, u'that GPUs love that you can do in things like convolutional neural networks. '), ('./static/6.mp4', 3166, u'But, you know, on the other hand, '), ('./static/6.mp4', 3168, u'we discovered that even though, um, '), ('./static/6.mp4', 3171, u'these gated recurrent units like LSTMs and GRUs are great, '), ('./static/6.mp4', 3176, u'that to get really great performance out of these recurrent models, '), ('./static/6.mp4', 3180, u'we found that we wanted to- we had a problem within these long sequence lengths, '), ('./static/6.mp4', 3185, u'and we can improve things by adding attention mechanisms. '), ('./static/6.mp4', 3189, u'And so that led to the idea of- well, '), ('./static/6.mp4', 3192, u'since attention works so great, '), ('./static/6.mp4', 3194, u'maybe we can just use attention, '), ('./static/6.mp4', 3197, u'and we can actually get rid of the recurrent part of the model [NOISE] altogether. '), ('./static/6.mp4', 3202, u'And so that actually then leads to the idea of these transformer architectures, '), ('./static/6.mp4', 3207, u'and the original paper on this is actually called attention is all you need, '), ('./static/6.mp4', 3212, u"which reflects this idea of we're gonna keep the attention part, "), ('./static/6.mp4', 3216, u"and we're getting- going to get rid of the, um, "), ('./static/6.mp4', 3220, u"recurrent part, and we'll be able to build a great model. "), ('./static/6.mp4', 3223, u'So in the initial work, '), ('./static/6.mp4', 3225, u"what they're doing is machine translation kind of like "), ('./static/6.mp4', 3228, u'the Neural Machine Translation with attention we described, '), ('./static/6.mp4', 3232, u"but what they're wanting to do is build "), ('./static/6.mp4', 3236, u'a complex encoder and a complex decoder that works non-recurrently, '), ('./static/6.mp4', 3243, u'and, um, nevertheless is able to translate sentences '), ('./static/6.mp4', 3247, u'well by making use of lots of attention distributions. '), ('./static/6.mp4', 3253, u'And so, I wanted to say a little bit more quickly about that, '), ('./static/6.mp4', 3258, u"and hopefully we'll get more of this on Thursday. "), ('./static/6.mp4', 3260, u'Um, first as a- as a recommended resource, '), ('./static/6.mp4', 3264, u'if you wanna look at, um, '), ('./static/6.mp4', 3266, u'home and learn more about, um, '), ('./static/6.mp4', 3269, u"the transformer architecture, there's this really great, um, "), ('./static/6.mp4', 3274, u'bit of work by Sasha Rush called The Annotated Transformer that goes through '), ('./static/6.mp4', 3279, u'the entire transformer paper accompanied by PyTorch code in a Jupyter Notebook, '), ('./static/6.mp4', 3285, u'and so that can actually be a really useful thing, '), ('./static/6.mp4', 3288, u"but I'll go through a little bit of the basics now of how we do things. "), ('./static/6.mp4', 3294, u'So the basic idea, um, '), ('./static/6.mp4', 3297, u"is that they're going to use attention everywhere to calculate things. "), ('./static/6.mp4', 3303, u'And, um, we talked before about the different kinds of '), ('./static/6.mp4', 3307, u'attention of the sort of multiplicative by linear attention and the little, '), ('./static/6.mp4', 3312, u'um, feed-forward network additive attention. '), ('./static/6.mp4', 3315, u'They kind of go for the simplest kind of attention, '), ('./static/6.mp4', 3318, u'where the attention is just dot-products between two things. '), ('./static/6.mp4', 3323, u'Um, but they sort of do the more comp- for various purposes, '), ('./static/6.mp4', 3326, u'they do the more complicated version of dot-product between two things where they have, '), ('./static/6.mp4', 3332, u"um, when the- the things that they're looking up are "), ('./static/6.mp4', 3336, u'assumed to be key-value pairs, keys and values, '), ('./static/6.mp4', 3340, u"and so you're calculating the similarity as a dot-product between a query and the key, "), ('./static/6.mp4', 3346, u'and then based on that, '), ('./static/6.mp4', 3348, u"you're going to be using the vector for the corresponding value. "), ('./static/6.mp4', 3352, u"So our equation here for what we're calculating is where you are "), ('./static/6.mp4', 3355, u'looking using the softmax over query, um, '), ('./static/6.mp4', 3360, u'key similarities and using that to give '), ('./static/6.mp4', 3363, u'the weightings as an attention based weighting over the corresponding values. '), ('./static/6.mp4', 3368, u"Um, so that's the basic attention model. "), ('./static/6.mp4', 3372, u'Um, so that add- saying it that way, um, '), ('./static/6.mp4', 3375, u'adds a little bit of complexity, '), ('./static/6.mp4', 3378, u'but sort of for the simplest part for their encoder. '), ('./static/6.mp4', 3381, u'Actually, all of the query keys and values are exactly the same. '), ('./static/6.mp4', 3386, u'They are the words, um, '), ('./static/6.mp4', 3388, u"that they're using as their source language, um, things. "), ('./static/6.mp4', 3392, u"So, it sort of adds some complexity that isn't really there. "), ('./static/6.mp4', 3398, u"Um, okay. Um, I'll skip that. "), ('./static/6.mp4', 3402, u'Um, so, there are a couple of other things that they do. '), ('./static/6.mp4', 3408, u'One thing that they note is that, um, '), ('./static/6.mp4', 3412, u'the- the values you get from, um, QTK, um, '), ('./static/6.mp4', 3417, u'very, in variances the dimension gets large '), ('./static/6.mp4', 3423, u'so that they sort of do some normalization by the size of the hidden state dimension, '), ('./static/6.mp4', 3428, u"but I'll leave that out as well for details, right. "), ('./static/6.mp4', 3432, u'So in the encoder, um, '), ('./static/6.mp4', 3433, u'everything is just our word vectors, '), ('./static/6.mp4', 3437, u'there are the queries, the keys, and the values. '), ('./static/6.mp4', 3440, u"Um, and we're gonna use attention everywhere in the system. "), ('./static/6.mp4', 3443, u'Oops. Okay. So the second new idea is, well, '), ('./static/6.mp4', 3449, u"attention is great but maybe it's bad if you only have one attention distribution, "), ('./static/6.mp4', 3456, u"because you're gonna only attend to things one way. "), ('./static/6.mp4', 3459, u'Maybe for various users it would be great '), ('./static/6.mp4', 3462, u'if you could attend from one position to various things. '), ('./static/6.mp4', 3465, u"So, if you're thinking about syntax and what we did with dependency parsers. "), ('./static/6.mp4', 3471, u"If you're a word, you might want to attend to your headword, "), ('./static/6.mp4', 3474, u'but you might also wanna attend- attend to your dependent words. '), ('./static/6.mp4', 3479, u'And if you happen to be a pronoun, '), ('./static/6.mp4', 3481, u'you might want to attend to what the pronoun refers to you. '), ('./static/6.mp4', 3486, u'You might want to have lots of attention. '), ('./static/6.mp4', 3487, u'So they introduced this idea of multi-head attention. '), ('./static/6.mp4', 3492, u"And so what you're doing with multi-head attention is you have, "), ('./static/6.mp4', 3496, u'um, your hidden states, '), ('./static/6.mp4', 3498, u'um, in your system, '), ('./static/6.mp4', 3500, u'and you map them via projection layers, um, '), ('./static/6.mp4', 3503, u'which are just multiplications by different W matrices as '), ('./static/6.mp4', 3507, u'linear projections into sort of different lower dimensional spaces, '), ('./static/6.mp4', 3512, u'and then you use each of those to calculate dot-product attention, '), ('./static/6.mp4', 3517, u'and so you can attend to different things at the same time. '), ('./static/6.mp4', 3520, u'And this multi-head attention was one of '), ('./static/6.mp4', 3522, u'the very successful ideas of transformers that made them a more powerful architecture. '), ('./static/6.mp4', 3528, u'Okay. Um, so, then for our complete transformer block, '), ('./static/6.mp4', 3534, u"it's sort of then starting to build complex architectures like we sort of started seeing, "), ('./static/6.mp4', 3540, u'um, the other week. '), ('./static/6.mp4', 3542, u'Um, so- okay. '), ('./static/6.mp4', 3545, u'Yeah. So, starting, '), ('./static/6.mp4', 3546, u'um, from our word vectors, '), ('./static/6.mp4', 3550, u"we're kind of going to do attention to multiple different things, "), ('./static/6.mp4', 3556, u"um, and we're simultaneously gonna have "), ('./static/6.mp4', 3559, u'a residual connection that short-circuits around them. '), ('./static/6.mp4', 3563, u"Um, we're then going to sort of sum the two of these, "), ('./static/6.mp4', 3568, u"and then they're going to do a normalization at that point. "), ('./static/6.mp4', 3573, u'Um, I talked previously about batch normalization, '), ('./static/6.mp4', 3576, u"they don't do batch normalization, "), ('./static/6.mp4', 3578, u'they do another variant which is layer normalization, '), ('./static/6.mp4', 3581, u'which is a different way of doing normalization, '), ('./static/6.mp4', 3583, u"but I'll skip that for now. "), ('./static/6.mp4', 3585, u'And then they sort of for one transformer block, '), ('./static/6.mp4', 3589, u'you then go after the multi-head attention, '), ('./static/6.mp4', 3592, u'you put things through a feed-forward layer which also has a residual connection, '), ('./static/6.mp4', 3596, u'you sum the output of those, '), ('./static/6.mp4', 3598, u'and you then again do another, um, layer normalization. '), ('./static/6.mp4', 3603, u"So this is the basic transformer block that they're gonna use everywhere. "), ('./static/6.mp4', 3608, u'And to make their complete architectures, '), ('./static/6.mp4', 3611, u"they're then gonna sort of start stacking "), ('./static/6.mp4', 3613, u'these transformer blocks to produce a very deep network. '), ('./static/6.mp4', 3617, u'And in some sense, '), ('./static/6.mp4', 3618, u'what has been found is that transformers performed very well. '), ('./static/6.mp4', 3622, u"But, you know, there's no free lunch, "), ('./static/6.mp4', 3625, u"um, you kind of can't. "), ('./static/6.mp4', 3626, u"You're- now, no longer getting "), ('./static/6.mp4', 3628, u'recurrent information actually being carried along a sequence. '), ('./static/6.mp4', 3631, u"You've got a word at some position which can be casting attention, "), ('./static/6.mp4', 3636, u'uh, on other words. '), ('./static/6.mp4', 3638, u"So if you'd like to have information carried along in a chain, "), ('./static/6.mp4', 3641, u"you've sort of first of all gotta walk the first step of the chain, "), ('./static/6.mp4', 3644, u'and then you need to have another layer '), ('./static/6.mp4', 3646, u'vertically which can walk the next step of the chain, '), ('./static/6.mp4', 3649, u'and then you need to have another layer vertically that walks the next step of the chain. '), ('./static/6.mp4', 3653, u"So, you're getting rid of the recurrence along the sequence, "), ('./static/6.mp4', 3657, u"but you're substituting some depth to allow things to walk along multiple hops. "), ('./static/6.mp4', 3663, u"But nevertheless, that's highly advantageous in GPU architectures "), ('./static/6.mp4', 3667, u'because it allows you to use parallelization to calculate everything at each, '), ('./static/6.mp4', 3673, u'um, depth at the same time. Um. '), ('./static/6.mp4', 3679, u"Maybe I'll go light on explaining this as well. "), ('./static/6.mp4', 3682, u'Um, so they use byte-pair encodings. '), ('./static/6.mp4', 3685, u'But if you do nothing else, '), ('./static/6.mp4', 3687, u'you just have words fed in this word vectors and you have '), ('./static/6.mp4', 3690, u"no idea whether you're at the beginning of the sentence or at the end of the sentence. "), ('./static/6.mp4', 3694, u'Though, they have a message of- method of doing positional encoding which gives '), ('./static/6.mp4', 3698, u'you some ideas to pro- position your word has in the sentence. '), ('./static/6.mp4', 3702, u"Okay. Um, so that's sort of the, um, encoder system. "), ('./static/6.mp4', 3707, u'So from the words, '), ('./static/6.mp4', 3709, u'they have an initial word embedding, '), ('./static/6.mp4', 3711, u'you add in their positional encoding, '), ('./static/6.mp4', 3714, u'you go into one of these transformer blocks, '), ('./static/6.mp4', 3718, u'and you then repeat it n times. '), ('./static/6.mp4', 3721, u"So you'll have a stack of these transformer blocks. "), ('./static/6.mp4', 3723, u"So you're multiple times doing, um, "), ('./static/6.mp4', 3726, u'multi-head attention to other parts of the sentence, calculating values, '), ('./static/6.mp4', 3731, u'feeding forward a value, '), ('./static/6.mp4', 3732, u'putting it through a fully-connected layer, '), ('./static/6.mp4', 3734, u'and then you just sort of repeat, do attention to different places in the sentence. '), ('./static/6.mp4', 3739, u'Get all your information, '), ('./static/6.mp4', 3741, u'put it through a fully connected layer, '), ('./static/6.mp4', 3743, u'and go up, um, proceeding up deeply. '), ('./static/6.mp4', 3746, u'And and that sounds a little mysterious, '), ('./static/6.mp4', 3751, u'but it turns out to work just great. '), ('./static/6.mp4', 3754, u'And the way to think about, '), ('./static/6.mp4', 3756, u'I think is that at each stage, '), ('./static/6.mp4', 3759, u'you can look with your multi-headed attention and various other places in the sentence, '), ('./static/6.mp4', 3764, u'accumulate information, push it up to the next layer. '), ('./static/6.mp4', 3768, u'And if you do that sort of half a dozen times, '), ('./static/6.mp4', 3771, u'you can be starting to progressively push information along '), ('./static/6.mp4', 3775, u'the sequence in either direction to calculate values that are of interest. '), ('./static/6.mp4', 3781, u'Um, and the interesting thing is that these models turn out to work '), ('./static/6.mp4', 3788, u'really well at sort of learning to attend the interesting things in linguistic structure. '), ('./static/6.mp4', 3795, u'Um, so these are just sort of suggestive diagrams, '), ('./static/6.mp4', 3799, u'but this is looking at layer five of the transformer stack and '), ('./static/6.mp4', 3804, u'seeing what words are being attended to by different attention heads. '), ('./static/6.mp4', 3808, u'So these different colors correspond to different attention heads. '), ('./static/6.mp4', 3813, u'And so the sentence is, '), ('./static/6.mp4', 3815, u'um, it is, "In this spirit, '), ('./static/6.mp4', 3819, u'that a majority of American governments have passed new laws since '), ('./static/6.mp4', 3822, u'2009 making the registration or voting process more difficult." '), ('./static/6.mp4', 3827, u'And so what we see is sort of most of the attention heads, '), ('./static/6.mp4', 3833, u'uh, looking from making to making more difficult and that seems to be useful. '), ('./static/6.mp4', 3838, u'One of the attention heads seems to be looking at the word itself might be okay. '), ('./static/6.mp4', 3843, u'Um, then the other ones are sort of looking a bit at laws and at 2009. '), ('./static/6.mp4', 3850, u"So it's sort of picking out the arguments, um, "), ('./static/6.mp4', 3854, u'and modifiers and making in a syntax kind of like way. '), ('./static/6.mp4', 3858, u'Um, interestingly, for pronouns, '), ('./static/6.mp4', 3861, u'attention heads appear to learn to be able to look back to reference. '), ('./static/6.mp4', 3866, u'So the law will never be perfect, '), ('./static/6.mp4', 3868, u'but its application should be just that one attention head it for its, '), ('./static/6.mp4', 3875, u'is looking at what its is modifying in the application. '), ('./static/6.mp4', 3879, u'But another attention head, '), ('./static/6.mp4', 3880, u'the its is looking strongly at what its refers back to as the law. '), ('./static/6.mp4', 3885, u'So that seems kind of cool. '), ('./static/6.mp4', 3887, u'Um, yeah. '), ('./static/6.mp4', 3889, u'Um, okay. '), ('./static/6.mp4', 3892, u'And so then, for the rest of the model, um, '), ('./static/6.mp4', 3896, u"there's then some more complexity for how to use "), ('./static/6.mp4', 3898, u'the transformers decoder to give you a full neural machine translation system. '), ('./static/6.mp4', 3905, u'But I think maybe I will skip that and go '), ('./static/6.mp4', 3908, u'on and say a bit about BERT in my remaining minutes. '), ('./static/6.mp4', 3913, u'Okay. So, um, the latest and greatest contextual '), ('./static/6.mp4', 3918, u'word representations to help you flow your tasks have been these BERT vectors, '), ('./static/6.mp4', 3923, u'where BERT is Bidirectional Encoder Representations from Transformers. '), ('./static/6.mp4', 3929, u"And so essentially, it's using the encoder from a transformer network. "), ('./static/6.mp4', 3935, u'Uh, this deep multi-headed attention stack to calculate, um, '), ('./static/6.mp4', 3940, u'a representation of a sentence and saying, '), ('./static/6.mp4', 3943, u'"That\'s a great all-purpose representation of a sentence that you can use for tasks. '), ('./static/6.mp4', 3949, u'Be it named entity recognition or SQuAD question answering." '), ('./static/6.mp4', 3954, u"And so there's actually an interesting new idea that these people had. "), ('./static/6.mp4', 3959, u'And that well, their idea was well standard language models are '), ('./static/6.mp4', 3964, u"unidirectional and that's useful "), ('./static/6.mp4', 3968, u'because it gives you a probability distribution of a language model. '), ('./static/6.mp4', 3971, u"But it's bad because you'd like to be able to do "), ('./static/6.mp4', 3976, u'prediction from both sides to understand word meaning and context. '), ('./static/6.mp4', 3981, u"There's a second choice, um, "), ('./static/6.mp4', 3983, u'which is you can kind of do bidirectional models when you incorporate, '), ('./static/6.mp4', 3989, u'um, information in both ways. '), ('./static/6.mp4', 3991, u'But that sort of has problems as well, '), ('./static/6.mp4', 3995, u'because then you get crosstalk. '), ('./static/6.mp4', 3997, u'Um, and so if you run a BiLSTM, '), ('./static/6.mp4', 4000, u'and then you merge the representations by '), ('./static/6.mp4', 4003, u'concatenation and then feed them into the next layer. '), ('./static/6.mp4', 4006, u"When you're running the next layer, "), ('./static/6.mp4', 4008, u'the forward LSTM will have already gotten '), ('./static/6.mp4', 4011, u'information about the future from the first layer. '), ('./static/6.mp4', 4014, u'Um, so it sort of, um, '), ('./static/6.mp4', 4016, u'ends up with words that have already seen the future themselves. '), ('./static/6.mp4', 4020, u'So you have this sort of complex non-generative model. '), ('./static/6.mp4', 4023, u'Um, so somehow, they wanted to do things a bit differently, '), ('./static/6.mp4', 4028, u'so they can have bidirectional context without words being able to see themselves. '), ('./static/6.mp4', 4033, u'And the idea that they came up with is well, '), ('./static/6.mp4', 4036, u"we're gonna train things with a transformer encoder. "), ('./static/6.mp4', 4041, u"But what we're gonna do is mask out some of the words in the sentence, "), ('./static/6.mp4', 4046, u"like, maybe we'll mask here store and gallon. "), ('./static/6.mp4', 4050, u'And then, so our language mod- our language modelling like '), ('./static/6.mp4', 4054, u'objective will no longer be '), ('./static/6.mp4', 4056, u"a true language model that's sort of generating a probability of a sentence, "), ('./static/6.mp4', 4060, u'um, which is standardly done by working from left to right, '), ('./static/6.mp4', 4063, u'but it will instead be a Mad Libs style fill in the blank objective. '), ('./static/6.mp4', 4069, u"So you'll see this context, "), ('./static/6.mp4', 4072, u'which will be literally, '), ('./static/6.mp4', 4073, u'"The man went to the mask to buy a mask of milk." '), ('./static/6.mp4', 4076, u"And your, what's your training objective is to say, "), ('./static/6.mp4', 4080, u'try and predict what this word is, '), ('./static/6.mp4', 4083, u"which you can do with a cross entropy loss to the extent that you don't guess store. "), ('./static/6.mp4', 4088, u'And then, it will be trying to guess what this word is and you want to let guess gallon. '), ('./static/6.mp4', 4092, u"So you're training a model, "), ('./static/6.mp4', 4094, u'um, to fill in these blanks. '), ('./static/6.mp4', 4097, u'Um, and the rate at which they blank words is essentially one word in seven, '), ('./static/6.mp4', 4102, u'and they discuss how this is a trade-off. '), ('./static/6.mp4', 4105, u'Because if you blank too few words, '), ('./static/6.mp4', 4108, u'it gets very expensive to train. '), ('./static/6.mp4', 4110, u'And if you blank many words, '), ('./static/6.mp4', 4112, u"well you've blanked out most of the context of a word, "), ('./static/6.mp4', 4115, u"and that means it's not very useful for training, "), ('./static/6.mp4', 4118, u'and they found about sort of one in seven seemed to work pretty well for them. '), ('./static/6.mp4', 4122, u'But what they want to argue is, um, '), ('./static/6.mp4', 4126, u"that for the OpenAI's GPT, "), ('./static/6.mp4', 4131, u'which is also a transformer model. '), ('./static/6.mp4', 4133, u"It's a sort of a classic language model working from "), ('./static/6.mp4', 4136, u'left to right and so you only get left context. '), ('./static/6.mp4', 4140, u'Um, for the BERT language model, '), ('./static/6.mp4', 4143, u"sorry, the ELMo language model that's shown up at the top. "), ('./static/6.mp4', 4147, u"Um, well, they're running a left to right language model and they're running, "), ('./static/6.mp4', 4151, u'um, right to left language models. '), ('./static/6.mp4', 4153, u'So in some sense, um, '), ('./static/6.mp4', 4156, u'they have context from both sides. '), ('./static/6.mp4', 4158, u'But these two language models are trained completely independently '), ('./static/6.mp4', 4162, u"and then you're just sort of concatenating their representations, um, together. "), ('./static/6.mp4', 4167, u"So there's no sense in which we're actually kind of having a model that's jointly "), ('./static/6.mp4', 4172, u'using context from both sides at the time though that the pre-trained, '), ('./static/6.mp4', 4177, u'um, contextual word representations are built. '), ('./static/6.mp4', 4180, u'So their hope is using inside a transformer model '), ('./static/6.mp4', 4185, u'this trick of blanking out words, '), ('./static/6.mp4', 4187, u'and predicting it using the entire context will allow them to use two-sided context, '), ('./static/6.mp4', 4193, u'and be much more effective. '), ('./static/6.mp4', 4195, u"And that's what they seem to show, um. "), ('./static/6.mp4', 4200, u"There's one other complication and, "), ('./static/6.mp4', 4203, u"I mean, I'll show later. "), ('./static/6.mp4', 4205, u'Um, this last complication is a bit useful, '), ('./static/6.mp4', 4209, u"but it's sort of not really essential to their main idea, "), ('./static/6.mp4', 4212, u'was that they thought, '), ('./static/6.mp4', 4214, u'one of the, one of the goals in their head was clearly to be able to '), ('./static/6.mp4', 4218, u'have this be useful for things like question answering, '), ('./static/6.mp4', 4222, u'um, tasks, or, um, '), ('./static/6.mp4', 4225, u'natural language inference tasks, '), ('./static/6.mp4', 4226, u'and their relationships between, um, two sentences. '), ('./static/6.mp4', 4230, u'So, their idea was, well, '), ('./static/6.mp4', 4232, u'one good objective is this fill in the blank word objective which is, '), ('./static/6.mp4', 4236, u'sort of, like language modeling objective. '), ('./static/6.mp4', 4239, u'But they thought it would be useful to have a second objective '), ('./static/6.mp4', 4242, u"where you're predicting relationships between sentences. "), ('./static/6.mp4', 4245, u'So, they secondly have a loss function which is, um, '), ('./static/6.mp4', 4251, u"let's have two sentences where "), ('./static/6.mp4', 4254, u'the sentences might be two successive sentences in the text, '), ('./static/6.mp4', 4258, u'or a sentence followed by a random sentence from somewhere else. '), ('./static/6.mp4', 4262, u"And we want to train the system to predict when you've, "), ('./static/6.mp4', 4266, u'seeing an- a correct next sentence versus a random sentence. '), ('./static/6.mp4', 4270, u"And so you're also training a loss based on this next sentence prediction task. "), ('./static/6.mp4', 4276, u"And so it'll be something like: The man went to the store. "), ('./static/6.mp4', 4279, u'He bought a gallon of milk. '), ('./static/6.mp4', 4281, u"You're meant to predict true is the next sentence, "), ('./static/6.mp4', 4284, u'um: The man went to the store. '), ('./static/6.mp4', 4286, u'Penguins are flightless. '), ('./static/6.mp4', 4288, u"You're meant to say false. "), ('./static/6.mp4', 4289, u"This isn't the next sentence. "), ('./static/6.mp4', 4291, u"And so they're simultaneously also, "), ('./static/6.mp4', 4293, u'um, training with this representation. '), ('./static/6.mp4', 4296, u'So, what they end up looks, looks like this. '), ('./static/6.mp4', 4300, u'Um, so, they have, '), ('./static/6.mp4', 4304, u'um, for the input, '), ('./static/6.mp4', 4305, u"they'll have a pair of sentences. "), ('./static/6.mp4', 4307, u'My dog is cute. '), ('./static/6.mp4', 4308, u'Um, separator. '), ('./static/6.mp4', 4310, u'He likes playing. '), ('./static/6.mp4', 4311, u'Um, the words are represented as word pieces like we talked about last week. '), ('./static/6.mp4', 4317, u"Um, so there's a token embedding for each word piece. "), ('./static/6.mp4', 4321, u"Um, then there's a positional embedding for "), ('./static/6.mp4', 4325, u'each word piece which is gonna be summed with the token embedding. '), ('./static/6.mp4', 4329, u"And then finally, there's a segment embedding for each word piece which is simply "), ('./static/6.mp4', 4334, u'whether it comes from the first sentence or '), ('./static/6.mp4', 4337, u'the second sentence before or after the separator. '), ('./static/6.mp4', 4339, u"So, you're summing those three things together to get the token representations. "), ('./static/6.mp4', 4344, u"And then you're going to use those in a transformer model "), ('./static/6.mp4', 4348, u"where you will have losses to the extent that you can't predict the masked words. "), ('./static/6.mp4', 4353, u"And then your binary prediction function as to whether there's "), ('./static/6.mp4', 4358, u'a correct next sentence or not which is the training architecture. '), ('./static/6.mp4', 4363, u"Okay. So, it's a transformer as before, "), ('./static/6.mp4', 4367, u"it's trained on Wikipedia plus the BookCorpus. "), ('./static/6.mp4', 4370, u'And they built two models. '), ('./static/6.mp4', 4372, u'Um, the Base-BERT model was a twelve layer transformer. '), ('./static/6.mp4', 4377, u'And so this corresponded to what the previous transformer paper had used, right? '), ('./static/6.mp4', 4382, u'Those two layer transformer blocks repeated six times gave you 12 layers with 768 hidden, '), ('./static/6.mp4', 4389, u'um, dimension hidden states and 12 heads for the multi-head attention. '), ('./static/6.mp4', 4394, u'And then they went bigger, '), ('./static/6.mp4', 4396, u'um, and trained BERT-Large which is, '), ('./static/6.mp4', 4398, u'sort of, double the number of layers, '), ('./static/6.mp4', 4400, u'bigger hidden states, even more attention heads. '), ('./static/6.mp4', 4403, u'Um, and training these on, '), ('./static/6.mp4', 4406, u'um, pods of TPUs. '), ('./static/6.mp4', 4409, u"Um, so, first of all, you're training, um, "), ('./static/6.mp4', 4413, u'on this basis for masked words and, '), ('./static/6.mp4', 4418, u'um, next sentence or not. '), ('./static/6.mp4', 4420, u'Um, so then what they wanted to say was this pre-trained model, '), ('./static/6.mp4', 4425, u'um, evaluated on these losses and masked language model and next sentence prediction. '), ('./static/6.mp4', 4431, u'Um, we could then take this model, '), ('./static/6.mp4', 4434, u"fr- freeze most of its what weak. No, sorry, that's wrong. "), ('./static/6.mp4', 4439, u'We could take this model, um, '), ('./static/6.mp4', 4441, u'pre-trained and it would be incredibly useful for various different tasks. '), ('./static/6.mp4', 4446, u'We could use it for named entity recognition, '), ('./static/6.mp4', 4448, u'question answering, natural language inference et cetera. '), ('./static/6.mp4', 4452, u"And the way we're going to do it, is kind of, "), ('./static/6.mp4', 4454, u'doing the same thing as the ULMFit model did. '), ('./static/6.mp4', 4458, u"We're not just going to say here's our, "), ('./static/6.mp4', 4460, u"here's a contextual word representation like ELMo did. "), ('./static/6.mp4', 4465, u"Instead, what we're gonna say is just keep on using this, "), ('./static/6.mp4', 4469, u'keep on using this um, '), ('./static/6.mp4', 4472, u'transformer network that we trained as a, sort of, '), ('./static/6.mp4', 4476, u'language model, but fine tune it for a particular task. '), ('./static/6.mp4', 4482, u"So, you're now going to run this transformer "), ('./static/6.mp4', 4485, u'calculating representations for a particular task. '), ('./static/6.mp4', 4489, u"And what we're going to change is we're going to remove the very top-level prediction. "), ('./static/6.mp4', 4495, u'The bits that predict the mass language model and next sentence prediction. '), ('./static/6.mp4', 4500, u"And we're going to substitute on it, "), ('./static/6.mp4', 4502, u"on top, um, a final prediction layer that's appropriate for the task. "), ('./static/6.mp4', 4508, u'So, if our task is SQuAD question answering, '), ('./static/6.mp4', 4511, u'our final prediction layer will be predicting start of span and end of span, '), ('./static/6.mp4', 4516, u'kind of, like when we saw DrQA a couple of weeks ago. '), ('./static/6.mp4', 4520, u"If what we're doing is the NER task, "), ('./static/6.mp4', 4523, u'our final prediction layer will be predicting '), ('./static/6.mp4', 4526, u'the net- named entity recognition class of each token just like a standard NER system. '), ('./static/6.mp4', 4533, u'Okay, um, and so they built this system and tested it on a whole bunch of data sets. '), ('./static/6.mp4', 4542, u'Um, one of the main things they tested on was '), ('./static/6.mp4', 4545, u'this GLUE data set which has a whole bunch of tasks. '), ('./static/6.mp4', 4548, u"A lot of the tasks, they're, "), ('./static/6.mp4', 4550, u'uh, natural language inference tasks. '), ('./static/6.mp4', 4553, u"And I've kept saying that phrase all of this lecture but I haven't really defined it. "), ('./static/6.mp4', 4557, u"So, with a natural language inference you're given two sentences "), ('./static/6.mp4', 4560, u'like: Hills and mountains are especially sanctified in Jainism. '), ('./static/6.mp4', 4565, u'And then you can write a hypothesis on: Jainism hates nature. '), ('./static/6.mp4', 4569, u"And what you're meant to say is, "), ('./static/6.mp4', 4571, u'whether the hypothesis, um, '), ('./static/6.mp4', 4573, u'follows from the premise, '), ('./static/6.mp4', 4575, u'contradicts the premise, or has no relation to the premise. '), ('./static/6.mp4', 4579, u"So, that's a three-way classification. "), ('./static/6.mp4', 4581, u'And so here it contradicts the premise. '), ('./static/6.mp4', 4583, u'Um, there are various other tasks such as this linguistic acceptability task. '), ('./static/6.mp4', 4590, u'Um, but if we look at these, um, GLUE tasks. '), ('./static/6.mp4', 4593, u'Um, these are showing the Pre-OpenAI State Of The Art. '), ('./static/6.mp4', 4597, u'How well, um, ELMo works. '), ('./static/6.mp4', 4600, u'How well OpenAI GPT works, '), ('./static/6.mp4', 4603, u'and then how well do small and large BERT models work. '), ('./static/6.mp4', 4608, u"And effectively, what you're finding is, "), ('./static/6.mp4', 4613, u'um, that the OpenAI GPT was so, '), ('./static/6.mp4', 4617, u'you know, pretty good. '), ('./static/6.mp4', 4618, u'It showed actually good advances on most of these tasks. '), ('./static/6.mp4', 4622, u'For many, but not all of them that broke the previous state of the art, '), ('./static/6.mp4', 4625, u'showing the power of these contextual language models. '), ('./static/6.mp4', 4628, u"But the bidirectional form of BERT's prediction just seemed much better again. "), ('./static/6.mp4', 4635, u"So, going from this line to this line you're getting depending on "), ('./static/6.mp4', 4639, u'the task about two percent better performance. '), ('./static/6.mp4', 4643, u'And so the BERT people actually did their experiments carefully. '), ('./static/6.mp4', 4647, u'So, these models are pretty comparable in terms of size, '), ('./static/6.mp4', 4650, u'but the bidirectional context seems to really help. '), ('./static/6.mp4', 4653, u'And then what they found was, '), ('./static/6.mp4', 4655, u'well, by going to just a bigger model, '), ('./static/6.mp4', 4657, u'again, you could get another big lift in performance. '), ('./static/6.mp4', 4661, u"And so you're getting for many of the tasks about "), ('./static/6.mp4', 4664, u'another two percent lift in performance going into the bigger model. '), ('./static/6.mp4', 4668, u'So, this really produced super-strong results. '), ('./static/6.mp4', 4671, u'And in general, um, people have found, '), ('./static/6.mp4', 4674, u'um, that BERT continues to give super strong results. '), ('./static/6.mp4', 4677, u'So, if I return back to my ConLL NER task, '), ('./static/6.mp4', 4681, u'we had ELMo giving you 92.2, '), ('./static/6.mp4', 4685, u'um, and you, sort of, '), ('./static/6.mp4', 4686, u'continue to get gains. '), ('./static/6.mp4', 4688, u'So, BERT Base gets you to 92.4 and BERT Large takes you to 92.8. '), ('./static/6.mp4', 4693, u'Though in, um, truth in, truth in description, '), ('./static/6.mp4', 4697, u'there is now a system of beats BERT Large on NER which is actually a character-level, '), ('./static/6.mp4', 4703, u'um, transformer language model from Flair. '), ('./static/6.mp4', 4705, u'Um, but, you know, '), ('./static/6.mp4', 4707, u'this continued over to a lot of other things. '), ('./static/6.mp4', 4710, u'So, on SQuAD 1.1, um, '), ('./static/6.mp4', 4713, u'BERT immediately just outperformed '), ('./static/6.mp4', 4716, u'everything else that people have been working on for SQuAD for ages. '), ('./static/6.mp4', 4719, u'In particular, what was especially dramatic, um, '), ('./static/6.mp4', 4722, u'was the sing- a single BERT model, um, '), ('./static/6.mp4', 4725, u'beat everything else that had been done previously on SQuAD version 1.1, '), ('./static/6.mp4', 4730, u'even though they could also show that an '), ('./static/6.mp4', 4733, u'ensemble of BERT models could give further good, um, performance gains. '), ('./static/6.mp4', 4739, u"Um, and as I've mentioned before, "), ('./static/6.mp4', 4743, u'essentially if you look at the SQuAD 2.0, um, '), ('./static/6.mp4', 4745, u'leaderboard, all of the top ranked systems, '), ('./static/6.mp4', 4748, u'um, are using BERT one place or another. '), ('./static/6.mp4', 4752, u'Um, and so that, '), ('./static/6.mp4', 4754, u'sort of, led into this, '), ('./static/6.mp4', 4756, u'sort of, new world order, um, that, okay, '), ('./static/6.mp4', 4759, u'it seems like the state of NLP now is to, '), ('./static/6.mp4', 4762, u'if you want to have the best performance, '), ('./static/6.mp4', 4765, u'you want to be using '), ('./static/6.mp4', 4766, u'these deep pre-trained transformer stacks to get the best performance. '), ('./static/6.mp4', 4771, u'And so this is, sort of, making, '), ('./static/6.mp4', 4773, u'um, NLP more like vision. '), ('./static/6.mp4', 4775, u'Because really vision for five years has had '), ('./static/6.mp4', 4778, u'these deep pre-trained neural network stacks, um, like ResNets. '), ('./static/6.mp4', 4782, u'Where for most vision tasks what you do is you take a pre-trained ResNet, '), ('./static/6.mp4', 4787, u'and then you fine tune a layer at the top to '), ('./static/6.mp4', 4789, u"do some classification tasks you're interested in. "), ('./static/6.mp4', 4792, u'And this is, sort of, now, um, '), ('./static/6.mp4', 4794, u"starting to be what's happening in NLP as well. "), ('./static/6.mp4', 4797, u'That you can do the same thing by downloading '), ('./static/6.mp4', 4800, u'your pre-trained BERT and fine tuning it to do some particular performance task. '), ('./static/6.mp4', 4805, u"Okay, um, that's it for today and more on "), ('./static/6.mp4', 4809, u'transformers on Thursday [NOISE]. ')]